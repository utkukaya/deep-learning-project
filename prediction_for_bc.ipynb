{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing.missing_value_imputation import missing_value_imputation\n",
    "from preprocessing.train_autoencoder import train_autoencoder\n",
    "from preprocessing.normalization import normalize_data\n",
    "from models.autoencoder import Autoencoder\n",
    "from models.cnn import CNN, CNNForBC\n",
    "from models.multilayerperceptron import MultilayerPerceptron, MultilayerPerceptronForPCA, MultilayerPerceptronForBC\n",
    "from helper.evals import precision, recall, f1_score, test_model, train_model, precision_recall_multiclass, prepare_train, train_model_k_fold, prepare_train_k_fold, prepare_train_k_fold_with_normalization_and_imputation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from helper.plot_graphs import plot_confusion_matrix, plot_train_and_test_set\n",
    "from torchsummary import summary\n",
    "from models.logistic_regression import LogisticRegression, LogisticRegressionForBC\n",
    "from Sklearn_PyTorch.random_forest import TorchRandomForestClassifier, TorchDecisionTreeRegressor\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Utku Sabri Kaya 504231535\n",
    "# Haniyeh Dousti 504211557\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prad_2019a_merged_data # PRAD\n",
    "# prad_2019b_merged_data # PRAD \n",
    "# prad_2014_merged_data # PRAD\n",
    "# coad_merged_data # COAD\n",
    "# pdac_merged_data # PDAC\n",
    "# rc20_merged_data # ccRCC4\n",
    "# rc18mr_merged_data # ccRCC3\n",
    "# brca_terunuma_merged_data # BRCA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc18mr_merged_data = pd.read_csv('edited dataset/merged_data/rc18mr_merged_data.csv')\n",
    "pdac_merged_data = pd.read_csv('edited dataset/merged_data/pdac_merged_data.csv')\n",
    "brca_terunuma_merged_data = pd.read_csv('edited dataset/merged_data/brca_terunuma_merged_data.csv')\n",
    "coad_merged_data = pd.read_csv('edited dataset/merged_data/coad_merged_data.csv')\n",
    "prad_2019a_merged_data = pd.read_csv('edited dataset/merged_data/prad_2019a_merged_data.csv')\n",
    "prad_2019b_merged_data = pd.read_csv('edited dataset/merged_data/prad_2019b_merged_data.csv')\n",
    "prad_2014_merged_data = pd.read_csv('edited dataset/merged_data/prad_2014_merged_data.csv')\n",
    "rc20_merged_data = pd.read_csv('edited dataset/merged_data/rc20_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc18mr_merged_data.insert(0, 'Labels', rc18mr_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "pdac_merged_data.insert(0, 'Labels', pdac_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "brca_terunuma_merged_data.insert(0, 'Labels', brca_terunuma_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "coad_merged_data.insert(0, 'Labels', coad_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "prad_2019a_merged_data.insert(0, 'Labels', prad_2019a_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "prad_2019b_merged_data.insert(0, 'Labels', prad_2019b_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "prad_2014_merged_data.insert(0, 'Labels', prad_2014_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n",
    "rc20_merged_data.insert(0, 'Labels', rc20_merged_data['TN'].apply(lambda x: 1 if x == 'Tumor' else 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc18mr_data = rc18mr_merged_data.iloc[:,5:]\n",
    "rc18mr_labels = rc18mr_merged_data.iloc[:,:1]\n",
    "\n",
    "pdac_data = pdac_merged_data.iloc[:,5:]\n",
    "pdac_labels = pdac_merged_data.iloc[:,:1]\n",
    "\n",
    "brca_terunuma_data = brca_terunuma_merged_data.iloc[:,5:]\n",
    "brca_terunuma_labels = brca_terunuma_merged_data.iloc[:,:1]\n",
    "\n",
    "coad_data = coad_merged_data.iloc[:,5:]\n",
    "coad_labels = coad_merged_data.iloc[:,:1]\n",
    "\n",
    "prad_2019a_data = prad_2019a_merged_data.iloc[:,5:]\n",
    "prad_2019a_labels = prad_2019a_merged_data.iloc[:,:1]\n",
    "\n",
    "prad_2019b_data = prad_2019b_merged_data.iloc[:,5:]\n",
    "prad_2019b_labels = prad_2019b_merged_data.iloc[:,:1]\n",
    "\n",
    "prad_2014_data = prad_2014_merged_data.iloc[:,5:]\n",
    "prad_2014_labels = prad_2014_merged_data.iloc[:,:1]\n",
    "\n",
    "rc20_data = rc20_merged_data.iloc[:,5:]\n",
    "rc20_labels = rc20_merged_data.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data):\n",
    "    X_train, X_test = train_test_split(data.values, test_size=0.2, random_state=42)\n",
    "\n",
    "    data_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    data_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    data_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "    input_dim = len(data.values[0])\n",
    "    encoding_dim = 2000 # len(data.values[0]) // 5\n",
    "    autoencoder = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "\n",
    "    autoencoder = train_autoencoder(\n",
    "                    model=Autoencoder(input_dim, encoding_dim), \n",
    "                    train_data=data_train_tensor,\n",
    "                    test_data=data_test_tensor, \n",
    "                    optimizer=optim.Adam(autoencoder.parameters(), lr=0.001), \n",
    "                    criterion=nn.MSELoss(), \n",
    "                    n_epoch=10)\n",
    "\n",
    "\n",
    "    data_dim_red = autoencoder.encoder(data_tensor)\n",
    "    return data_dim_red\n",
    "\n",
    "def remove_zero_columns(data):\n",
    "    return data.loc[:, (data != 0.0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan\n",
      "Epoch [10/10], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "rc18mr_data_dim_red = remove_zero_columns((pd.DataFrame(feature_extraction(rc18mr_data).detach().numpy())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 28303)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prad_2019a_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [prad_2019a_data, coad_data, pdac_data, rc18mr_data, rc20_data, brca_terunuma_data]\n",
    "labels = [prad_2019a_labels, coad_labels, pdac_labels, rc18mr_labels, rc20_labels, brca_terunuma_labels]\n",
    "names = ['PRAD', 'COAD', 'PDAC', 'ccRCC3', 'ccRCC4', 'BRCA']\n",
    "train_losses_cnn = {}\n",
    "train_accs_cnn = {}\n",
    "train_points_cnn = {}\n",
    "test_losses_cnn = {}\n",
    "test_accs_cnn = {}\n",
    "test_points_cnn = {}\n",
    "train_precs_cnn = {}\n",
    "train_recalls_cnn = {}\n",
    "train_f1s_cnn = {}\n",
    "test_precs_cnn = {}\n",
    "test_recalls_cnn = {}\n",
    "test_f1s_cnn = {}\n",
    "models_cnn = {}\n",
    "\n",
    "train_losses_mlp = {}\n",
    "train_accs_mlp = {}\n",
    "train_points_mlp = {}\n",
    "test_losses_mlp = {}\n",
    "test_accs_mlp = {}\n",
    "test_points_mlp = {}\n",
    "train_precs_mlp = {}\n",
    "train_recalls_mlp = {}\n",
    "train_f1s_mlp = {}\n",
    "test_precs_mlp = {}\n",
    "test_recalls_mlp = {}\n",
    "test_f1s_mlp = {}\n",
    "models_mlp = {}\n",
    "\n",
    "train_losses_logistic_regression = {}\n",
    "train_accs_logistic_regression = {}\n",
    "train_points_logistic_regression = {}\n",
    "test_losses_logistic_regression = {}\n",
    "test_accs_logistic_regression = {}\n",
    "test_points_logistic_regression = {}\n",
    "train_precs_logistic_regression = {}\n",
    "train_recalls_logistic_regression = {}\n",
    "train_f1s_logistic_regression = {}\n",
    "test_precs_logistic_regression = {}\n",
    "test_recalls_logistic_regression = {}\n",
    "test_f1s_logistic_regression = {}\n",
    "models_logistic_regression = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0484\n",
      "Epoch [10/10], Loss: 0.0518\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.70635, Accuracy: 31.34328\n",
      "TEST:\tEpoch:   0, Loss: 0.70635, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1574\n",
      "Epoch [10/10], Loss: 0.1588\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.62183, Accuracy: 68.65672\n",
      "TEST:\tEpoch:  10, Loss: 0.62183, Accuracy: 75.00000\n",
      "Test Loss: 0.1592\n",
      "Epoch [10/10], Loss: 0.1601\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.60945, Accuracy: 70.14925\n",
      "TEST:\tEpoch:  20, Loss: 0.60945, Accuracy: 62.50000\n",
      "Test Loss: 0.1613\n",
      "Epoch [10/10], Loss: 0.1623\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  30, Loss: 0.61022, Accuracy: 70.14925\n",
      "TEST:\tEpoch:  30, Loss: 0.61022, Accuracy: 62.50000\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.61262, Accuracy: 70.14925\n",
      "TEST:\tEpoch:  40, Loss: 0.61262, Accuracy: 62.50000\n",
      "TEST:\tEpoch:  49, Loss: 0.56313, Accuracy: 62.50000\n",
      "Test Loss: 0.1642\n",
      "Epoch [10/10], Loss: 0.1643\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.63482, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  50, Loss: 0.63482, Accuracy: 71.42857\n",
      "Test Loss: 0.1626\n",
      "Epoch [10/10], Loss: 0.1630\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.63729, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  60, Loss: 0.63729, Accuracy: 71.42857\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1657\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.61529, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  70, Loss: 0.61529, Accuracy: 71.42857\n",
      "Test Loss: 0.1656\n",
      "Epoch [10/10], Loss: 0.1648\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.63805, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  80, Loss: 0.63805, Accuracy: 71.42857\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1660\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.62407, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  90, Loss: 0.62407, Accuracy: 42.85714\n",
      "Test Loss: 0.0583\n",
      "Epoch [10/10], Loss: 0.0578\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69293, Accuracy: 51.47059\n",
      "TEST:\tEpoch:   0, Loss: 0.69293, Accuracy: 50.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1600\n",
      "Epoch [10/10], Loss: 0.1584\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.69356, Accuracy: 51.47059\n",
      "TEST:\tEpoch:  10, Loss: 0.69356, Accuracy: 50.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1632\n",
      "Epoch [10/10], Loss: 0.1620\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.69310, Accuracy: 50.00000\n",
      "TEST:\tEpoch:  20, Loss: 0.69310, Accuracy: 50.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1630\n",
      "Epoch [10/10], Loss: 0.1633\n",
      "(76, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  30, Loss: 0.69846, Accuracy: 51.47059\n",
      "TEST:\tEpoch:  30, Loss: 0.69846, Accuracy: 50.00000\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.71791, Accuracy: 48.52941\n",
      "TEST:\tEpoch:  40, Loss: 0.71791, Accuracy: 50.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\tEpoch:  49, Loss: 0.56048, Accuracy: 100.00000\n",
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1672\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.71949, Accuracy: 48.52941\n",
      "TEST:\tEpoch:  50, Loss: 0.71949, Accuracy: 50.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1660\n",
      "Epoch [10/10], Loss: 0.1663\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.72614, Accuracy: 52.17391\n",
      "TEST:\tEpoch:  60, Loss: 0.72614, Accuracy: 57.14286\n",
      "Test Loss: 0.1687\n",
      "Epoch [10/10], Loss: 0.1681\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.63829, Accuracy: 69.56522\n",
      "TEST:\tEpoch:  70, Loss: 0.63829, Accuracy: 57.14286\n",
      "Test Loss: 0.1646\n",
      "Epoch [10/10], Loss: 0.1638\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.88361, Accuracy: 50.72464\n",
      "TEST:\tEpoch:  80, Loss: 0.88361, Accuracy: 57.14286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1665\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.66634, Accuracy: 63.76812\n",
      "TEST:\tEpoch:  90, Loss: 0.66634, Accuracy: 28.57143\n",
      "Test Loss: 0.0728\n",
      "Epoch [10/10], Loss: 0.0665\n",
      "(39, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:   0, Loss: 0.70581, Accuracy: 28.57143\n",
      "TEST:\tEpoch:   0, Loss: 0.70581, Accuracy: 50.00000\n",
      "Test Loss: 0.1620\n",
      "Epoch [10/10], Loss: 0.1604\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.59897, Accuracy: 71.42857\n",
      "TEST:\tEpoch:  10, Loss: 0.59897, Accuracy: 50.00000\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1652\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.62722, Accuracy: 68.57143\n",
      "TEST:\tEpoch:  20, Loss: 0.62722, Accuracy: 75.00000\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1645\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  30, Loss: 0.63189, Accuracy: 68.57143\n",
      "TEST:\tEpoch:  30, Loss: 0.63189, Accuracy: 75.00000\n",
      "Test Loss: 0.1677\n",
      "Epoch [10/10], Loss: 0.1675\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.68228, Accuracy: 68.57143\n",
      "TEST:\tEpoch:  40, Loss: 0.68228, Accuracy: 75.00000\n",
      "TEST:\tEpoch:  49, Loss: 0.45924, Accuracy: 75.00000\n",
      "Test Loss: 0.1688\n",
      "Epoch [10/10], Loss: 0.1678\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.65728, Accuracy: 68.57143\n",
      "TEST:\tEpoch:  50, Loss: 0.65728, Accuracy: 75.00000\n",
      "Test Loss: 0.1693\n",
      "Epoch [10/10], Loss: 0.1692\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.67968, Accuracy: 51.42857\n",
      "TEST:\tEpoch:  60, Loss: 0.67968, Accuracy: 75.00000\n",
      "Test Loss: 0.1680\n",
      "Epoch [10/10], Loss: 0.1673\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.62802, Accuracy: 62.85714\n",
      "TEST:\tEpoch:  70, Loss: 0.62802, Accuracy: 50.00000\n",
      "Test Loss: 0.1686\n",
      "Epoch [10/10], Loss: 0.1685\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.70835, Accuracy: 57.14286\n",
      "TEST:\tEpoch:  80, Loss: 0.70835, Accuracy: 75.00000\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1676\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.87355, Accuracy: 69.44444\n",
      "TEST:\tEpoch:  90, Loss: 0.87355, Accuracy: 33.33333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1054\n",
      "Epoch [10/10], Loss: 0.1052\n",
      "(114, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:   0, Loss: 0.69506, Accuracy: 41.17647\n",
      "TEST:\tEpoch:   0, Loss: 0.69506, Accuracy: 58.33333\n",
      "Test Loss: 0.1579\n",
      "Epoch [10/10], Loss: 0.1581\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.68128, Accuracy: 58.82353\n",
      "TEST:\tEpoch:  10, Loss: 0.68128, Accuracy: 58.33333\n",
      "Test Loss: 0.1632\n",
      "Epoch [10/10], Loss: 0.1628\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.66963, Accuracy: 58.82353\n",
      "TEST:\tEpoch:  20, Loss: 0.66963, Accuracy: 75.00000\n",
      "Test Loss: 0.1651\n",
      "Epoch [10/10], Loss: 0.1648\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  30, Loss: 0.81596, Accuracy: 58.82353\n",
      "TEST:\tEpoch:  30, Loss: 0.81596, Accuracy: 41.66667\n",
      "Test Loss: 0.1650\n",
      "Epoch [10/10], Loss: 0.1651\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.65993, Accuracy: 61.16505\n",
      "TEST:\tEpoch:  40, Loss: 0.65993, Accuracy: 54.54545\n",
      "TEST:\tEpoch:  49, Loss: 0.54407, Accuracy: 63.63636\n",
      "Test Loss: 0.1687\n",
      "Epoch [10/10], Loss: 0.1682\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.67081, Accuracy: 59.22330\n",
      "TEST:\tEpoch:  50, Loss: 0.67081, Accuracy: 54.54545\n",
      "Test Loss: 0.1675\n",
      "Epoch [10/10], Loss: 0.1677\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.74866, Accuracy: 58.25243\n",
      "TEST:\tEpoch:  60, Loss: 0.74866, Accuracy: 27.27273\n",
      "Test Loss: 0.1638\n",
      "Epoch [10/10], Loss: 0.1641\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.68942, Accuracy: 58.25243\n",
      "TEST:\tEpoch:  70, Loss: 0.68942, Accuracy: 54.54545\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.69646, Accuracy: 52.42718\n",
      "TEST:\tEpoch:  80, Loss: 0.69646, Accuracy: 36.36364\n",
      "Test Loss: 0.1637\n",
      "Epoch [10/10], Loss: 0.1644\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.74223, Accuracy: 58.25243\n",
      "TEST:\tEpoch:  90, Loss: 0.74223, Accuracy: 27.27273\n",
      "Test Loss: 0.1316\n",
      "Epoch [10/10], Loss: 0.1284\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.72433, Accuracy: 32.35294\n",
      "TEST:\tEpoch:   0, Loss: 0.72433, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1650\n",
      "Epoch [10/10], Loss: 0.1624\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.64009, Accuracy: 67.64706\n",
      "TEST:\tEpoch:  10, Loss: 0.64009, Accuracy: 75.00000\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.61849, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  20, Loss: 0.61849, Accuracy: 62.50000\n",
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1666\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  30, Loss: 0.61014, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  30, Loss: 0.61014, Accuracy: 62.50000\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.67501, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  40, Loss: 0.67501, Accuracy: 62.50000\n",
      "TEST:\tEpoch:  49, Loss: 0.36800, Accuracy: 100.00000\n",
      "Test Loss: 0.1651\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.61362, Accuracy: 69.11765\n",
      "TEST:\tEpoch:  50, Loss: 0.61362, Accuracy: 75.00000\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1651\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.72945, Accuracy: 68.11594\n",
      "TEST:\tEpoch:  60, Loss: 0.72945, Accuracy: 100.00000\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1660\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.59880, Accuracy: 65.21739\n",
      "TEST:\tEpoch:  70, Loss: 0.59880, Accuracy: 57.14286\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.79692, Accuracy: 62.31884\n",
      "TEST:\tEpoch:  80, Loss: 0.79692, Accuracy: 57.14286\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1658\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.60008, Accuracy: 62.31884\n",
      "TEST:\tEpoch:  90, Loss: 0.60008, Accuracy: 71.42857\n",
      "Test Loss: 0.0547\n",
      "Epoch [10/10], Loss: 0.0542\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69165, Accuracy: 56.70103\n",
      "TEST:\tEpoch:   0, Loss: 0.69165, Accuracy: 54.54545\n",
      "Test Loss: 0.1588\n",
      "Epoch [10/10], Loss: 0.1587\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  10, Loss: 0.68557, Accuracy: 56.70103\n",
      "TEST:\tEpoch:  10, Loss: 0.68557, Accuracy: 54.54545\n",
      "Test Loss: 0.1617\n",
      "Epoch [10/10], Loss: 0.1626\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  20, Loss: 0.68368, Accuracy: 56.70103\n",
      "TEST:\tEpoch:  20, Loss: 0.68368, Accuracy: 54.54545\n",
      "Test Loss: 0.1667\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  30, Loss: 0.68089, Accuracy: 56.70103\n",
      "TEST:\tEpoch:  30, Loss: 0.68089, Accuracy: 54.54545\n",
      "Test Loss: 0.1673\n",
      "Epoch [10/10], Loss: 0.1669\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  40, Loss: 0.67668, Accuracy: 57.73196\n",
      "TEST:\tEpoch:  40, Loss: 0.67668, Accuracy: 54.54545\n",
      "TEST:\tEpoch:  49, Loss: 0.62715, Accuracy: 54.54545\n",
      "Test Loss: 0.1680\n",
      "Epoch [10/10], Loss: 0.1675\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  50, Loss: 0.65922, Accuracy: 56.70103\n",
      "TEST:\tEpoch:  50, Loss: 0.65922, Accuracy: 54.54545\n",
      "Test Loss: 0.1672\n",
      "Epoch [10/10], Loss: 0.1669\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  60, Loss: 0.64881, Accuracy: 52.57732\n",
      "TEST:\tEpoch:  60, Loss: 0.64881, Accuracy: 54.54545\n",
      "Test Loss: 0.1660\n",
      "Epoch [10/10], Loss: 0.1660\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  70, Loss: 0.65840, Accuracy: 58.76289\n",
      "TEST:\tEpoch:  70, Loss: 0.65840, Accuracy: 90.90909\n",
      "Test Loss: 0.1653\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  80, Loss: 0.64420, Accuracy: 58.16327\n",
      "TEST:\tEpoch:  80, Loss: 0.64420, Accuracy: 70.00000\n",
      "Test Loss: 0.1650\n",
      "Epoch [10/10], Loss: 0.1643\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:  90, Loss: 0.67178, Accuracy: 55.10204\n",
      "TEST:\tEpoch:  90, Loss: 0.67178, Accuracy: 30.00000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datas)):\n",
    "    model_autoencoder_cnn = CNN(input_size=500, output_size=2)\n",
    "    model_autoencoder_cnn, train_accs_autoencoder_cnn, train_losses_autoencoder_cnn, train_points_autoencoder_cnn, train_prec_autoencoder_cnn, train_recall_autoencoder_cnn, train_f1_autoencoder_cnn, test_accs_autoencoder_cnn, test_losses_autoencoder_cnn, test_points_autoencoder_cnn, test_prec_autoencoder_cnn, test_recall_autoencoder_cnn, test_f1_autoencoder_cnn = prepare_train_k_fold_with_normalization_and_imputation(model_autoencoder_cnn, datas[i].values, labels[i]['Labels'].values, reshape_size=datas[i].shape[1], n_epochs=10)\n",
    "    train_accs_cnn[names[i]] = train_accs_autoencoder_cnn\n",
    "    train_losses_cnn[names[i]] = train_losses_autoencoder_cnn\n",
    "    train_points_cnn[names[i]] = train_points_autoencoder_cnn\n",
    "    train_precs_cnn[names[i]] = train_prec_autoencoder_cnn\n",
    "    train_recalls_cnn[names[i]] = train_recall_autoencoder_cnn\n",
    "    train_f1s_cnn[names[i]] = train_f1_autoencoder_cnn\n",
    "    test_accs_cnn[names[i]] = test_accs_autoencoder_cnn\n",
    "    test_losses_cnn[names[i]] = test_losses_autoencoder_cnn\n",
    "    test_points_cnn[names[i]] = test_points_autoencoder_cnn\n",
    "    test_precs_cnn[names[i]] = test_prec_autoencoder_cnn\n",
    "    test_recalls_cnn[names[i]] = test_recall_autoencoder_cnn\n",
    "    test_f1s_cnn[names[i]] = test_f1_autoencoder_cnn\n",
    "    models_cnn[names[i]] = model_autoencoder_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0484\n",
      "Epoch [10/10], Loss: 0.0519\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.70828, Accuracy: 31.34328\n",
      "TEST:\tEpoch:   0, Loss: 0.70828, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.58648, Accuracy: 68.65672\n",
      "TEST:\tEpoch:  10, Loss: 0.58648, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.44637, Accuracy: 73.13433\n",
      "TEST:\tEpoch:  20, Loss: 0.44637, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.21368, Accuracy: 95.52239\n",
      "TEST:\tEpoch:  30, Loss: 0.21368, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.03030, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.03030, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00159, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00159, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00032, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00032, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00014, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00014, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00010, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00010, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00008, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00008, Accuracy: 87.50000\n",
      "Test Loss: 0.1547\n",
      "Epoch [10/10], Loss: 0.1559\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 3.54082, Accuracy: 68.65672\n",
      "TEST:\tEpoch: 100, Loss: 3.54082, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.39677, Accuracy: 79.10448\n",
      "TEST:\tEpoch: 110, Loss: 0.39677, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 120, Loss: 0.16635, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 120, Loss: 0.16635, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.11221, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 130, Loss: 0.11221, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.06458, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.06458, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.03693, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.03693, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.02329, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.02329, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.01595, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.01595, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.01173, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.01173, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00911, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00911, Accuracy: 87.50000\n",
      "Test Loss: 0.1618\n",
      "Epoch [10/10], Loss: 0.1621\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 3.78618, Accuracy: 70.14925\n",
      "TEST:\tEpoch: 200, Loss: 3.78618, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.88319, Accuracy: 71.64179\n",
      "TEST:\tEpoch: 210, Loss: 0.88319, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.28602, Accuracy: 91.04478\n",
      "TEST:\tEpoch: 220, Loss: 0.28602, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.21127, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 230, Loss: 0.21127, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.13566, Accuracy: 98.50746\n",
      "TEST:\tEpoch: 240, Loss: 0.13566, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.07029, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.07029, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.03073, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.03073, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.01340, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.01340, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00675, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00675, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00408, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00408, Accuracy: 62.50000\n",
      "Test Loss: 0.1638\n",
      "Epoch [10/10], Loss: 0.1634\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 1.58781, Accuracy: 73.13433\n",
      "TEST:\tEpoch: 300, Loss: 1.58781, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.28517, Accuracy: 92.53731\n",
      "TEST:\tEpoch: 310, Loss: 0.28517, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.09452, Accuracy: 98.50746\n",
      "TEST:\tEpoch: 320, Loss: 0.09452, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.04275, Accuracy: 98.50746\n",
      "TEST:\tEpoch: 330, Loss: 0.04275, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.01560, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.01560, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00672, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00672, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00339, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00339, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00223, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00223, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00159, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00159, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00123, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00123, Accuracy: 62.50000\n",
      "Test Loss: 0.1653\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 1.26542, Accuracy: 67.16418\n",
      "TEST:\tEpoch: 400, Loss: 1.26542, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.28634, Accuracy: 91.04478\n",
      "TEST:\tEpoch: 410, Loss: 0.28634, Accuracy: 37.50000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.11508, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 420, Loss: 0.11508, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.05331, Accuracy: 98.50746\n",
      "TEST:\tEpoch: 430, Loss: 0.05331, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.01068, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.01068, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00417, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00417, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00198, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00198, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00143, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00143, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00109, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00109, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00090, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00090, Accuracy: 50.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00078, Accuracy: 50.00000\n",
      "Test Loss: 0.1680\n",
      "Epoch [10/10], Loss: 0.1682\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 2.14498, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 500, Loss: 2.14498, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 510, Loss: 0.46150, Accuracy: 82.35294\n",
      "TEST:\tEpoch: 510, Loss: 0.46150, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 520, Loss: 0.23364, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 520, Loss: 0.23364, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 530, Loss: 0.07565, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.07565, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 540, Loss: 0.01799, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.01799, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00263, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00263, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00064, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00064, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00025, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00025, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00013, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00013, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00007, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00007, Accuracy: 57.14286\n",
      "Test Loss: 0.1675\n",
      "Epoch [10/10], Loss: 0.1660\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 4.35373, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 600, Loss: 4.35373, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 610, Loss: 0.55411, Accuracy: 76.47059\n",
      "TEST:\tEpoch: 610, Loss: 0.55411, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 620, Loss: 0.30138, Accuracy: 86.76471\n",
      "TEST:\tEpoch: 620, Loss: 0.30138, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 630, Loss: 0.15706, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 630, Loss: 0.15706, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 640, Loss: 0.06751, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.06751, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 650, Loss: 0.02279, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.02279, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00722, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00722, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00321, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00321, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00197, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00197, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00141, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00141, Accuracy: 100.00000\n",
      "Test Loss: 0.1656\n",
      "Epoch [10/10], Loss: 0.1658\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.14046, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 700, Loss: 2.14046, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 710, Loss: 0.43139, Accuracy: 77.94118\n",
      "TEST:\tEpoch: 710, Loss: 0.43139, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 720, Loss: 0.14303, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.14303, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 730, Loss: 0.06574, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.06574, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 740, Loss: 0.02220, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.02220, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 750, Loss: 0.01038, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.01038, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00590, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00590, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00393, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00393, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00305, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00305, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00246, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00246, Accuracy: 71.42857\n",
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.14336, Accuracy: 57.35294\n",
      "TEST:\tEpoch: 800, Loss: 1.14336, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 810, Loss: 0.21280, Accuracy: 94.11765\n",
      "TEST:\tEpoch: 810, Loss: 0.21280, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 820, Loss: 0.04324, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.04324, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.01405, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.01405, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00702, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00702, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00455, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00455, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00344, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00344, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00279, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00279, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00237, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00237, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00206, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00206, Accuracy: 57.14286\n",
      "Test Loss: 0.1619\n",
      "Epoch [10/10], Loss: 0.1625\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.67508, Accuracy: 66.17647\n",
      "TEST:\tEpoch: 900, Loss: 1.67508, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 910, Loss: 0.36946, Accuracy: 82.35294\n",
      "TEST:\tEpoch: 910, Loss: 0.36946, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 920, Loss: 0.10501, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 920, Loss: 0.10501, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 930, Loss: 0.02899, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.02899, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 940, Loss: 0.01446, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.01446, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00717, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00717, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00368, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00368, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00216, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00216, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00153, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00153, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00118, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00118, Accuracy: 85.71429\n",
      "Test Loss: 0.0583\n",
      "Epoch [10/10], Loss: 0.0579\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69414, Accuracy: 48.52941\n",
      "TEST:\tEpoch:   0, Loss: 0.69414, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.29096, Accuracy: 94.11765\n",
      "TEST:\tEpoch:  10, Loss: 0.29096, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.11867, Accuracy: 97.05882\n",
      "TEST:\tEpoch:  20, Loss: 0.11867, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.05940, Accuracy: 98.52941\n",
      "TEST:\tEpoch:  30, Loss: 0.05940, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.04406, Accuracy: 98.52941\n",
      "TEST:\tEpoch:  40, Loss: 0.04406, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00388, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00388, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00045, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00045, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00021, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00021, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00006, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00006, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00005, Accuracy: 87.50000\n",
      "Test Loss: 0.1618\n",
      "Epoch [10/10], Loss: 0.1597\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 1.73474, Accuracy: 48.52941\n",
      "TEST:\tEpoch: 100, Loss: 1.73474, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.19700, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 110, Loss: 0.19700, Accuracy: 87.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 120, Loss: 0.09888, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 120, Loss: 0.09888, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.06384, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 130, Loss: 0.06384, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.04374, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 140, Loss: 0.04374, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.02456, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 150, Loss: 0.02456, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.00856, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.00856, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00169, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00169, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00058, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00058, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00027, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00027, Accuracy: 87.50000\n",
      "Test Loss: 0.1622\n",
      "Epoch [10/10], Loss: 0.1609\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 2.05450, Accuracy: 41.17647\n",
      "TEST:\tEpoch: 200, Loss: 2.05450, Accuracy: 37.50000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.16458, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 210, Loss: 0.16458, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.02887, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 220, Loss: 0.02887, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.00778, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.00778, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.00416, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.00416, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00243, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00243, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00158, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00158, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00117, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00117, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00091, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00091, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00075, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00075, Accuracy: 100.00000\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1643\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 1.40767, Accuracy: 60.29412\n",
      "TEST:\tEpoch: 300, Loss: 1.40767, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.12649, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 310, Loss: 0.12649, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.05039, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 320, Loss: 0.05039, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.01501, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.01501, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.00622, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.00622, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00379, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00379, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00271, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00271, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00200, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00200, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00130, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00130, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00082, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00082, Accuracy: 100.00000\n",
      "Test Loss: 0.1679\n",
      "Epoch [10/10], Loss: 0.1674\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 1.66420, Accuracy: 41.17647\n",
      "TEST:\tEpoch: 400, Loss: 1.66420, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.12620, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 410, Loss: 0.12620, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.01964, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.01964, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.00720, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.00720, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00405, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00405, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00244, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00244, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00172, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00172, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00120, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00120, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00074, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00074, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00047, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00047, Accuracy: 87.50000\n",
      "TEST:\tEpoch: 499, Loss: 0.00035, Accuracy: 87.50000\n",
      "Test Loss: 0.1661\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 1.87971, Accuracy: 50.00000\n",
      "TEST:\tEpoch: 500, Loss: 1.87971, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.15898, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 510, Loss: 0.15898, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.03143, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.03143, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.01267, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.01267, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.00527, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.00527, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00227, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00227, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00117, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00117, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00078, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00078, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00059, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00059, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00048, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00048, Accuracy: 100.00000\n",
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1675\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 3.22572, Accuracy: 47.82609\n",
      "TEST:\tEpoch: 600, Loss: 3.22572, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 610, Loss: 0.54749, Accuracy: 71.01449\n",
      "TEST:\tEpoch: 610, Loss: 0.54749, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 620, Loss: 0.26962, Accuracy: 89.85507\n",
      "TEST:\tEpoch: 620, Loss: 0.26962, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 630, Loss: 0.10376, Accuracy: 97.10145\n",
      "TEST:\tEpoch: 630, Loss: 0.10376, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 640, Loss: 0.02477, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.02477, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 650, Loss: 0.00593, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.00593, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00185, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00185, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00079, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00079, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00043, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00043, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00029, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00029, Accuracy: 71.42857\n",
      "Test Loss: 0.1644\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.26587, Accuracy: 46.37681\n",
      "TEST:\tEpoch: 700, Loss: 2.26587, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 710, Loss: 0.06795, Accuracy: 98.55072\n",
      "TEST:\tEpoch: 710, Loss: 0.06795, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 720, Loss: 0.01582, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.01582, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 730, Loss: 0.00645, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.00645, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00353, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00353, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00239, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00239, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00179, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00179, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00144, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00144, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00120, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00120, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00102, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00102, Accuracy: 100.00000\n",
      "Test Loss: 0.1648\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.61230, Accuracy: 50.72464\n",
      "TEST:\tEpoch: 800, Loss: 1.61230, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 810, Loss: 0.22414, Accuracy: 92.75362\n",
      "TEST:\tEpoch: 810, Loss: 0.22414, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 820, Loss: 0.04902, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.04902, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.01733, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.01733, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00779, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00779, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00406, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00406, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00262, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00262, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00182, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00182, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00136, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00136, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00108, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00108, Accuracy: 85.71429\n",
      "Test Loss: 0.1654\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.32849, Accuracy: 47.82609\n",
      "TEST:\tEpoch: 900, Loss: 1.32849, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 910, Loss: 0.13413, Accuracy: 95.65217\n",
      "TEST:\tEpoch: 910, Loss: 0.13413, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 920, Loss: 0.02241, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.02241, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 930, Loss: 0.00582, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.00582, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00281, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00281, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00193, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00193, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00154, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00154, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00131, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00131, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00115, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00115, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00103, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00103, Accuracy: 100.00000\n",
      "Test Loss: 0.0729\n",
      "Epoch [10/10], Loss: 0.0666\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.68376, Accuracy: 71.42857\n",
      "TEST:\tEpoch:   0, Loss: 0.68376, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.39805, Accuracy: 80.00000\n",
      "TEST:\tEpoch:  10, Loss: 0.39805, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.21237, Accuracy: 91.42857\n",
      "TEST:\tEpoch:  20, Loss: 0.21237, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.14743, Accuracy: 94.28571\n",
      "TEST:\tEpoch:  30, Loss: 0.14743, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.10865, Accuracy: 94.28571\n",
      "TEST:\tEpoch:  40, Loss: 0.10865, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00572, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00572, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00046, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00046, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00014, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00014, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00005, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00003, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00003, Accuracy: 100.00000\n",
      "Test Loss: 0.1635\n",
      "Epoch [10/10], Loss: 0.1614\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 3.77337, Accuracy: 71.42857\n",
      "TEST:\tEpoch: 100, Loss: 3.77337, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.28875, Accuracy: 91.42857\n",
      "TEST:\tEpoch: 110, Loss: 0.28875, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 120, Loss: 0.13952, Accuracy: 91.42857\n",
      "TEST:\tEpoch: 120, Loss: 0.13952, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.05929, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 130, Loss: 0.05929, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.03643, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.03643, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.01877, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.01877, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01011, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.01011, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00546, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00546, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00326, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00326, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00205, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00205, Accuracy: 100.00000\n",
      "Test Loss: 0.1666\n",
      "Epoch [10/10], Loss: 0.1650\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 1.29138, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 200, Loss: 1.29138, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.16845, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 210, Loss: 0.16845, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.01001, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 220, Loss: 0.01001, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 230, Loss: 0.00706, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.00706, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.00278, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.00278, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00214, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00214, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00189, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00189, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00161, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00161, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00143, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00143, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00130, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00130, Accuracy: 100.00000\n",
      "Test Loss: 0.1688\n",
      "Epoch [10/10], Loss: 0.1667\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 1.82993, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 300, Loss: 1.82993, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.25403, Accuracy: 91.42857\n",
      "TEST:\tEpoch: 310, Loss: 0.25403, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.02640, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.02640, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 330, Loss: 0.01276, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.01276, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.00588, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.00588, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00419, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00419, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00307, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00307, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00255, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00255, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00217, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00217, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00187, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00187, Accuracy: 100.00000\n",
      "Test Loss: 0.1682\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 1.03178, Accuracy: 74.28571\n",
      "TEST:\tEpoch: 400, Loss: 1.03178, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.19510, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 410, Loss: 0.19510, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.01601, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.01601, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.00645, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.00645, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00353, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00353, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00267, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00267, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00209, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00209, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00180, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00180, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00158, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00158, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00140, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00140, Accuracy: 75.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00128, Accuracy: 75.00000\n",
      "Test Loss: 0.1705\n",
      "Epoch [10/10], Loss: 0.1690\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 1.23698, Accuracy: 71.42857\n",
      "TEST:\tEpoch: 500, Loss: 1.23698, Accuracy: 0.00000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.18586, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 510, Loss: 0.18586, Accuracy: 0.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.01419, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.01419, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.00800, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.00800, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.00317, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.00317, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00259, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00259, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00203, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00203, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00169, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00169, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00149, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00149, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00133, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00133, Accuracy: 50.00000\n",
      "Test Loss: 0.1698\n",
      "Epoch [10/10], Loss: 0.1696\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.20819, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 600, Loss: 1.20819, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 610, Loss: 0.09825, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 610, Loss: 0.09825, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 620, Loss: 0.02232, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 620, Loss: 0.02232, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 630, Loss: 0.00563, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.00563, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 640, Loss: 0.00289, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.00289, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 650, Loss: 0.00195, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.00195, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00151, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00151, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00101, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00101, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00065, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00065, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00045, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00045, Accuracy: 75.00000\n",
      "Test Loss: 0.1661\n",
      "Epoch [10/10], Loss: 0.1650\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.29299, Accuracy: 60.00000\n",
      "TEST:\tEpoch: 700, Loss: 1.29299, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 710, Loss: 0.04808, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 710, Loss: 0.04808, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 720, Loss: 0.00966, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.00966, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 730, Loss: 0.00317, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.00317, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00171, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00171, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00124, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00124, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00102, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00102, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00087, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00087, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00077, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00077, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00069, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00069, Accuracy: 100.00000\n",
      "Test Loss: 0.1670\n",
      "Epoch [10/10], Loss: 0.1657\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.35134, Accuracy: 48.57143\n",
      "TEST:\tEpoch: 800, Loss: 1.35134, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 810, Loss: 0.03161, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 810, Loss: 0.03161, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 820, Loss: 0.00515, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.00515, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 830, Loss: 0.00204, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.00204, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00124, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00124, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00092, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00092, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00076, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00076, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00066, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00066, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00059, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00059, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00053, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00053, Accuracy: 75.00000\n",
      "Test Loss: 0.1627\n",
      "Epoch [10/10], Loss: 0.1627\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.32271, Accuracy: 50.00000\n",
      "TEST:\tEpoch: 900, Loss: 1.32271, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 910, Loss: 0.05158, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 910, Loss: 0.05158, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 920, Loss: 0.00950, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.00950, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 930, Loss: 0.00284, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.00284, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00141, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00141, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00098, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00098, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00078, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00078, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00067, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00067, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00059, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00059, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00053, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00053, Accuracy: 66.66667\n",
      "Test Loss: 0.1053\n",
      "Epoch [10/10], Loss: 0.1051\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.68024, Accuracy: 58.82353\n",
      "TEST:\tEpoch:   0, Loss: 0.68024, Accuracy: 58.33333\n",
      "TRAIN:\tEpoch:  10, Loss: 0.31461, Accuracy: 92.15686\n",
      "TEST:\tEpoch:  10, Loss: 0.31461, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.02540, Accuracy: 99.01961\n",
      "TEST:\tEpoch:  20, Loss: 0.02540, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.00047, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.00047, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00009, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00009, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00004, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00004, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00003, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00002, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00002, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00002, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00002, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00002, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00002, Accuracy: 100.00000\n",
      "Test Loss: 0.1590\n",
      "Epoch [10/10], Loss: 0.1584\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 4.10780, Accuracy: 58.82353\n",
      "TEST:\tEpoch: 100, Loss: 4.10780, Accuracy: 58.33333\n",
      "TRAIN:\tEpoch: 110, Loss: 0.16501, Accuracy: 91.17647\n",
      "TEST:\tEpoch: 110, Loss: 0.16501, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 120, Loss: 0.02608, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 120, Loss: 0.02608, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 130, Loss: 0.00428, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 130, Loss: 0.00428, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 140, Loss: 0.00417, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.00417, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 150, Loss: 0.00243, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.00243, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 160, Loss: 0.00205, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.00205, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00170, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00170, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00140, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00140, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00118, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00118, Accuracy: 83.33333\n",
      "Test Loss: 0.1629\n",
      "Epoch [10/10], Loss: 0.1623\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 3.03776, Accuracy: 58.82353\n",
      "TEST:\tEpoch: 200, Loss: 3.03776, Accuracy: 58.33333\n",
      "TRAIN:\tEpoch: 210, Loss: 0.19371, Accuracy: 96.07843\n",
      "TEST:\tEpoch: 210, Loss: 0.19371, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 220, Loss: 0.11218, Accuracy: 95.09804\n",
      "TEST:\tEpoch: 220, Loss: 0.11218, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 230, Loss: 0.05003, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 230, Loss: 0.05003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.03102, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.03102, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.01544, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.01544, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00749, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00749, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00414, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00414, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00241, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00241, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00151, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00151, Accuracy: 100.00000\n",
      "Test Loss: 0.1648\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 1.57261, Accuracy: 34.31373\n",
      "TEST:\tEpoch: 300, Loss: 1.57261, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.08235, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 310, Loss: 0.08235, Accuracy: 83.33333\n",
      "TRAIN:\tEpoch: 320, Loss: 0.01648, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.01648, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 330, Loss: 0.00478, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.00478, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 340, Loss: 0.00250, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.00250, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00171, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00171, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00136, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00136, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00114, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00114, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00100, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00100, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00089, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00089, Accuracy: 91.66667\n",
      "Test Loss: 0.1646\n",
      "Epoch [10/10], Loss: 0.1642\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 1.91912, Accuracy: 35.92233\n",
      "TEST:\tEpoch: 400, Loss: 1.91912, Accuracy: 36.36364\n",
      "TRAIN:\tEpoch: 410, Loss: 0.15067, Accuracy: 96.11650\n",
      "TEST:\tEpoch: 410, Loss: 0.15067, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.05776, Accuracy: 98.05825\n",
      "TEST:\tEpoch: 420, Loss: 0.05776, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.02142, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.02142, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00905, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00905, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00435, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00435, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00240, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00240, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00150, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00150, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00105, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00105, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00081, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00081, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00067, Accuracy: 100.00000\n",
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1653\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 1.95446, Accuracy: 46.60194\n",
      "TEST:\tEpoch: 500, Loss: 1.95446, Accuracy: 36.36364\n",
      "TRAIN:\tEpoch: 510, Loss: 0.21074, Accuracy: 94.17476\n",
      "TEST:\tEpoch: 510, Loss: 0.21074, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 520, Loss: 0.06651, Accuracy: 99.02913\n",
      "TEST:\tEpoch: 520, Loss: 0.06651, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 530, Loss: 0.02336, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.02336, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.01341, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.01341, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00881, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00881, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00628, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00628, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00493, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00493, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00402, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00402, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00340, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00340, Accuracy: 100.00000\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1658\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.15638, Accuracy: 54.36893\n",
      "TEST:\tEpoch: 600, Loss: 1.15638, Accuracy: 36.36364\n",
      "TRAIN:\tEpoch: 610, Loss: 0.26090, Accuracy: 92.23301\n",
      "TEST:\tEpoch: 610, Loss: 0.26090, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 620, Loss: 0.06022, Accuracy: 98.05825\n",
      "TEST:\tEpoch: 620, Loss: 0.06022, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 630, Loss: 0.01965, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.01965, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 640, Loss: 0.01019, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.01019, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 650, Loss: 0.00697, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.00697, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00507, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00507, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00407, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00407, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00342, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00342, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00296, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00296, Accuracy: 90.90909\n",
      "Test Loss: 0.1667\n",
      "Epoch [10/10], Loss: 0.1667\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.33231, Accuracy: 57.28155\n",
      "TEST:\tEpoch: 700, Loss: 2.33231, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 710, Loss: 0.54949, Accuracy: 71.84466\n",
      "TEST:\tEpoch: 710, Loss: 0.54949, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 720, Loss: 0.15592, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.15592, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 730, Loss: 0.08659, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.08659, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.03908, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.03908, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.01953, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.01953, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.01204, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.01204, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00869, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00869, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00665, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00665, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00542, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00542, Accuracy: 100.00000\n",
      "Test Loss: 0.1684\n",
      "Epoch [10/10], Loss: 0.1684\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.58444, Accuracy: 41.74757\n",
      "TEST:\tEpoch: 800, Loss: 1.58444, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 810, Loss: 0.55358, Accuracy: 79.61165\n",
      "TEST:\tEpoch: 810, Loss: 0.55358, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 820, Loss: 0.20539, Accuracy: 95.14563\n",
      "TEST:\tEpoch: 820, Loss: 0.20539, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 830, Loss: 0.09923, Accuracy: 98.05825\n",
      "TEST:\tEpoch: 830, Loss: 0.09923, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 840, Loss: 0.04730, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.04730, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 850, Loss: 0.02431, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.02431, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 860, Loss: 0.01434, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.01434, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00969, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00969, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00722, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00722, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00574, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00574, Accuracy: 90.90909\n",
      "Test Loss: 0.1632\n",
      "Epoch [10/10], Loss: 0.1628\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.40932, Accuracy: 57.28155\n",
      "TEST:\tEpoch: 900, Loss: 1.40932, Accuracy: 27.27273\n",
      "TRAIN:\tEpoch: 910, Loss: 0.56906, Accuracy: 72.81553\n",
      "TEST:\tEpoch: 910, Loss: 0.56906, Accuracy: 36.36364\n",
      "TRAIN:\tEpoch: 920, Loss: 0.20564, Accuracy: 96.11650\n",
      "TEST:\tEpoch: 920, Loss: 0.20564, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 930, Loss: 0.09467, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.09467, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 940, Loss: 0.04640, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.04640, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 950, Loss: 0.02367, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.02367, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 960, Loss: 0.01432, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.01432, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00993, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00993, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00752, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00752, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00604, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00604, Accuracy: 81.81818\n",
      "Test Loss: 0.1315\n",
      "Epoch [10/10], Loss: 0.1285\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.71832, Accuracy: 32.35294\n",
      "TEST:\tEpoch:   0, Loss: 0.71832, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.28530, Accuracy: 95.58824\n",
      "TEST:\tEpoch:  10, Loss: 0.28530, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.14608, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  20, Loss: 0.14608, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.02430, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.02430, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00041, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00041, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00003, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00001, Accuracy: 100.00000\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 10.17305, Accuracy: 67.64706\n",
      "TEST:\tEpoch: 100, Loss: 10.17305, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.12832, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 110, Loss: 0.12832, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 120, Loss: 0.16379, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 120, Loss: 0.16379, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.11659, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 130, Loss: 0.11659, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.05991, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.05991, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.02717, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.02717, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01118, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.01118, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00499, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00499, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00268, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00268, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00169, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00169, Accuracy: 100.00000\n",
      "Test Loss: 0.1654\n",
      "Epoch [10/10], Loss: 0.1644\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 4.78879, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 200, Loss: 4.78879, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.66739, Accuracy: 41.17647\n",
      "TEST:\tEpoch: 210, Loss: 0.66739, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.29399, Accuracy: 91.17647\n",
      "TEST:\tEpoch: 220, Loss: 0.29399, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.02554, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.02554, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.00279, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.00279, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00057, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00057, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00031, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00031, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00023, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00023, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00020, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00020, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00018, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00018, Accuracy: 100.00000\n",
      "Test Loss: 0.1678\n",
      "Epoch [10/10], Loss: 0.1667\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 4.14034, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 300, Loss: 4.14034, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.35315, Accuracy: 76.47059\n",
      "TEST:\tEpoch: 310, Loss: 0.35315, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.15351, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.15351, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.05088, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.05088, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.01673, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.01673, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00652, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00652, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00343, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00343, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00226, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00226, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00167, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00167, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00132, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00132, Accuracy: 100.00000\n",
      "Test Loss: 0.1637\n",
      "Epoch [10/10], Loss: 0.1624\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 2.82098, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 400, Loss: 2.82098, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.45592, Accuracy: 73.52941\n",
      "TEST:\tEpoch: 410, Loss: 0.45592, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.15094, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.15094, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.04187, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.04187, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.01678, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.01678, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00751, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00751, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00427, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00427, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00271, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00271, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00190, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00190, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00144, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00144, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00117, Accuracy: 100.00000\n",
      "Test Loss: 0.1667\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 2.17584, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 500, Loss: 2.17584, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.40525, Accuracy: 80.88235\n",
      "TEST:\tEpoch: 510, Loss: 0.40525, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.24036, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.24036, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.11574, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.11574, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.05615, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.05615, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.02830, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.02830, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.01652, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.01652, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.01082, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.01082, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00780, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00780, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00601, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00601, Accuracy: 100.00000\n",
      "Test Loss: 0.1672\n",
      "Epoch [10/10], Loss: 0.1666\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 2.04277, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 600, Loss: 2.04277, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 610, Loss: 0.65061, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 610, Loss: 0.65061, Accuracy: 71.42857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 620, Loss: 0.18461, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 620, Loss: 0.18461, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 630, Loss: 0.08699, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.08699, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 640, Loss: 0.04858, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.04858, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 650, Loss: 0.02649, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.02649, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 660, Loss: 0.01638, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.01638, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 670, Loss: 0.01173, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.01173, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00881, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00881, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00699, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00699, Accuracy: 100.00000\n",
      "Test Loss: 0.1685\n",
      "Epoch [10/10], Loss: 0.1684\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.63038, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 700, Loss: 1.63038, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 710, Loss: 0.54177, Accuracy: 69.56522\n",
      "TEST:\tEpoch: 710, Loss: 0.54177, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 720, Loss: 0.14338, Accuracy: 97.10145\n",
      "TEST:\tEpoch: 720, Loss: 0.14338, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 730, Loss: 0.06504, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.06504, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 740, Loss: 0.03162, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.03162, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 750, Loss: 0.01906, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.01906, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 760, Loss: 0.01304, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.01304, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00932, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00932, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00704, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00704, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00534, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00534, Accuracy: 71.42857\n",
      "Test Loss: 0.1672\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.75731, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 800, Loss: 1.75731, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 810, Loss: 0.63163, Accuracy: 72.46377\n",
      "TEST:\tEpoch: 810, Loss: 0.63163, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 820, Loss: 0.19549, Accuracy: 92.75362\n",
      "TEST:\tEpoch: 820, Loss: 0.19549, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.09411, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.09411, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 840, Loss: 0.04363, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.04363, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 850, Loss: 0.02327, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.02327, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 860, Loss: 0.01503, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.01503, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 870, Loss: 0.01033, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.01033, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00729, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00729, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00541, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00541, Accuracy: 100.00000\n",
      "Test Loss: 0.1636\n",
      "Epoch [10/10], Loss: 0.1635\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 0.92462, Accuracy: 60.86957\n",
      "TEST:\tEpoch: 900, Loss: 0.92462, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 910, Loss: 0.32809, Accuracy: 85.50725\n",
      "TEST:\tEpoch: 910, Loss: 0.32809, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 920, Loss: 0.08765, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.08765, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 930, Loss: 0.02952, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.02952, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 940, Loss: 0.01278, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.01278, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00715, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00715, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00469, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00469, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00329, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00329, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00232, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00232, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00160, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00160, Accuracy: 85.71429\n",
      "Test Loss: 0.0548\n",
      "Epoch [10/10], Loss: 0.0543\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69448, Accuracy: 43.29897\n",
      "TEST:\tEpoch:   0, Loss: 0.69448, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch:  10, Loss: 0.43533, Accuracy: 90.72165\n",
      "TEST:\tEpoch:  10, Loss: 0.43533, Accuracy: 90.90909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.18250, Accuracy: 93.81443\n",
      "TEST:\tEpoch:  20, Loss: 0.18250, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  30, Loss: 0.04747, Accuracy: 98.96907\n",
      "TEST:\tEpoch:  30, Loss: 0.04747, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00608, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00608, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00091, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00091, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00036, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00036, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00022, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00022, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00016, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00016, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00012, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00012, Accuracy: 90.90909\n",
      "Test Loss: 0.1577\n",
      "Epoch [10/10], Loss: 0.1573\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 1.35929, Accuracy: 58.76289\n",
      "TEST:\tEpoch: 100, Loss: 1.35929, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 110, Loss: 0.28173, Accuracy: 87.62887\n",
      "TEST:\tEpoch: 110, Loss: 0.28173, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 120, Loss: 0.20531, Accuracy: 94.84536\n",
      "TEST:\tEpoch: 120, Loss: 0.20531, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 130, Loss: 0.11290, Accuracy: 94.84536\n",
      "TEST:\tEpoch: 130, Loss: 0.11290, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 140, Loss: 0.04571, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.04571, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.02256, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.02256, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01046, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.01046, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00574, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00574, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00363, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00363, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00257, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00257, Accuracy: 100.00000\n",
      "Test Loss: 0.1615\n",
      "Epoch [10/10], Loss: 0.1610\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 4.40405, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 200, Loss: 4.40405, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 210, Loss: 0.63015, Accuracy: 58.76289\n",
      "TEST:\tEpoch: 210, Loss: 0.63015, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 220, Loss: 0.41185, Accuracy: 90.72165\n",
      "TEST:\tEpoch: 220, Loss: 0.41185, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 230, Loss: 0.25814, Accuracy: 89.69072\n",
      "TEST:\tEpoch: 230, Loss: 0.25814, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 240, Loss: 0.19335, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 240, Loss: 0.19335, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 250, Loss: 0.14818, Accuracy: 95.87629\n",
      "TEST:\tEpoch: 250, Loss: 0.14818, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 260, Loss: 0.10118, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 260, Loss: 0.10118, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 270, Loss: 0.07743, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 270, Loss: 0.07743, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 280, Loss: 0.06108, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 280, Loss: 0.06108, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 290, Loss: 0.01536, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.01536, Accuracy: 81.81818\n",
      "Test Loss: 0.1649\n",
      "Epoch [10/10], Loss: 0.1643\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 1.54151, Accuracy: 51.54639\n",
      "TEST:\tEpoch: 300, Loss: 1.54151, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 310, Loss: 0.19154, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 310, Loss: 0.19154, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 320, Loss: 0.08005, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 320, Loss: 0.08005, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 330, Loss: 0.04791, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 330, Loss: 0.04791, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 340, Loss: 0.01688, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.01688, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00684, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00684, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00392, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00392, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00263, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00263, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00194, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00194, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00153, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00153, Accuracy: 90.90909\n",
      "Test Loss: 0.1651\n",
      "Epoch [10/10], Loss: 0.1650\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 2.74320, Accuracy: 55.67010\n",
      "TEST:\tEpoch: 400, Loss: 2.74320, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 410, Loss: 0.46135, Accuracy: 75.25773\n",
      "TEST:\tEpoch: 410, Loss: 0.46135, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 420, Loss: 0.24352, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 420, Loss: 0.24352, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 430, Loss: 0.12656, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 430, Loss: 0.12656, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 440, Loss: 0.04462, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 440, Loss: 0.04462, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00954, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00954, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00343, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00343, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00174, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00174, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00112, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00112, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00084, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00084, Accuracy: 81.81818\n",
      "TEST:\tEpoch: 499, Loss: 0.00069, Accuracy: 81.81818\n",
      "Test Loss: 0.1682\n",
      "Epoch [10/10], Loss: 0.1681\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 3.02562, Accuracy: 57.73196\n",
      "TEST:\tEpoch: 500, Loss: 3.02562, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 510, Loss: 0.34244, Accuracy: 85.56701\n",
      "TEST:\tEpoch: 510, Loss: 0.34244, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 520, Loss: 0.21052, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 520, Loss: 0.21052, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 530, Loss: 0.12975, Accuracy: 96.90722\n",
      "TEST:\tEpoch: 530, Loss: 0.12975, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 540, Loss: 0.05303, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.05303, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 550, Loss: 0.02293, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.02293, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 560, Loss: 0.01295, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.01295, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00852, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00852, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00551, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00551, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00348, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00348, Accuracy: 81.81818\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 2.89621, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 600, Loss: 2.89621, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 610, Loss: 0.45370, Accuracy: 77.31959\n",
      "TEST:\tEpoch: 610, Loss: 0.45370, Accuracy: 18.18182\n",
      "TRAIN:\tEpoch: 620, Loss: 0.38410, Accuracy: 84.53608\n",
      "TEST:\tEpoch: 620, Loss: 0.38410, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 630, Loss: 0.25167, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 630, Loss: 0.25167, Accuracy: 36.36364\n",
      "TRAIN:\tEpoch: 640, Loss: 0.13456, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 640, Loss: 0.13456, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 650, Loss: 0.08476, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 650, Loss: 0.08476, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 660, Loss: 0.06499, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 660, Loss: 0.06499, Accuracy: 45.45455\n",
      "TRAIN:\tEpoch: 670, Loss: 0.02337, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.02337, Accuracy: 27.27273\n",
      "TRAIN:\tEpoch: 680, Loss: 0.01082, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.01082, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00742, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00742, Accuracy: 45.45455\n",
      "Test Loss: 0.1675\n",
      "Epoch [10/10], Loss: 0.1677\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.86162, Accuracy: 55.67010\n",
      "TEST:\tEpoch: 700, Loss: 2.86162, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 710, Loss: 0.87772, Accuracy: 58.76289\n",
      "TEST:\tEpoch: 710, Loss: 0.87772, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 720, Loss: 0.51658, Accuracy: 81.44330\n",
      "TEST:\tEpoch: 720, Loss: 0.51658, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 730, Loss: 0.39516, Accuracy: 87.62887\n",
      "TEST:\tEpoch: 730, Loss: 0.39516, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 740, Loss: 0.22559, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 740, Loss: 0.22559, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 750, Loss: 0.09891, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 750, Loss: 0.09891, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 760, Loss: 0.01941, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.01941, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00655, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00655, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00318, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00318, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00195, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00195, Accuracy: 90.90909\n",
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1674\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.04592, Accuracy: 63.26531\n",
      "TEST:\tEpoch: 800, Loss: 1.04592, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 810, Loss: 0.10038, Accuracy: 98.97959\n",
      "TEST:\tEpoch: 810, Loss: 0.10038, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 820, Loss: 0.01483, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.01483, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 830, Loss: 0.00789, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.00789, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00493, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00493, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00381, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00381, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00308, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00308, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00258, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00258, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00226, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00226, Accuracy: 90.00000\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00200, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00200, Accuracy: 90.00000\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.50624, Accuracy: 44.89796\n",
      "TEST:\tEpoch: 900, Loss: 1.50624, Accuracy: 60.00000\n",
      "TRAIN:\tEpoch: 910, Loss: 0.15549, Accuracy: 98.97959\n",
      "TEST:\tEpoch: 910, Loss: 0.15549, Accuracy: 70.00000\n",
      "TRAIN:\tEpoch: 920, Loss: 0.03214, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.03214, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 930, Loss: 0.01048, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.01048, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00582, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00582, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00407, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00407, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00322, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00322, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00270, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00270, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00233, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00233, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00205, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00205, Accuracy: 80.00000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datas)):\n",
    "    model_autoencoder_logistic_regression = LogisticRegressionForBC(input_size=2000, output_size=2)\n",
    "    model_autoencoder_logistic_regression, train_accs_autoencoder_logistic_regression, train_losses_autoencoder_logistic_regression, train_points_autoencoder_logistic_regression, train_prec_autoencoder_logistic_regression, train_recall_autoencoder_logistic_regression, train_f1_autoencoder_logistic_regression, test_accs_autoencoder_logistic_regression, test_losses_autoencoder_logistic_regression, test_points_autoencoder_logistic_regression, test_prec_autoencoder_logistic_regression, test_recall_autoencoder_logistic_regression, test_f1_autoencoder_logistic_regression = prepare_train_k_fold_with_normalization_and_imputation(model_autoencoder_logistic_regression, datas[i].values, labels[i]['Labels'].values, reshape_size=datas[i].shape[1], n_epochs=100)\n",
    "    train_accs_logistic_regression[names[i]] = train_accs_autoencoder_logistic_regression\n",
    "    train_losses_logistic_regression[names[i]] = train_losses_autoencoder_logistic_regression\n",
    "    train_points_logistic_regression[names[i]] = train_points_autoencoder_logistic_regression\n",
    "    train_precs_logistic_regression[names[i]] = train_prec_autoencoder_logistic_regression\n",
    "    train_recalls_logistic_regression[names[i]] = train_recall_autoencoder_logistic_regression\n",
    "    train_f1s_logistic_regression[names[i]] = train_f1_autoencoder_logistic_regression\n",
    "    test_accs_logistic_regression[names[i]] = test_accs_autoencoder_logistic_regression\n",
    "    test_losses_logistic_regression[names[i]] = test_losses_autoencoder_logistic_regression\n",
    "    test_points_logistic_regression[names[i]] = test_points_autoencoder_logistic_regression\n",
    "    test_precs_logistic_regression[names[i]] = test_prec_autoencoder_logistic_regression\n",
    "    test_recalls_logistic_regression[names[i]] = test_recall_autoencoder_logistic_regression\n",
    "    test_f1s_logistic_regression[names[i]] = test_f1_autoencoder_logistic_regression\n",
    "\n",
    "    models_logistic_regression[names[i]] = model_autoencoder_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 28303)\n",
      "Test Loss: 0.0483\n",
      "Epoch [10/10], Loss: 0.0518\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69869, Accuracy: 31.34328\n",
      "TEST:\tEpoch:   0, Loss: 0.69869, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.57863, Accuracy: 68.65672\n",
      "TEST:\tEpoch:  10, Loss: 0.57863, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.40453, Accuracy: 68.65672\n",
      "TEST:\tEpoch:  20, Loss: 0.40453, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.20751, Accuracy: 95.52239\n",
      "TEST:\tEpoch:  30, Loss: 0.20751, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.02271, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.02271, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00140, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00140, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00022, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00022, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00009, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00009, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00005, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00004, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00004, Accuracy: 87.50000\n",
      "Test Loss: 0.1560\n",
      "Epoch [10/10], Loss: 0.1571\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 5.25175, Accuracy: 68.65672\n",
      "TEST:\tEpoch: 100, Loss: 5.25175, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.47140, Accuracy: 73.13433\n",
      "TEST:\tEpoch: 110, Loss: 0.47140, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 120, Loss: 0.31481, Accuracy: 80.59701\n",
      "TEST:\tEpoch: 120, Loss: 0.31481, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.18009, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 130, Loss: 0.18009, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.11012, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.11012, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.06396, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.06396, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.03615, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.03615, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.02035, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.02035, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.01203, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.01203, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00779, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00779, Accuracy: 75.00000\n",
      "Test Loss: 0.1581\n",
      "Epoch [10/10], Loss: 0.1597\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 1.38674, Accuracy: 61.19403\n",
      "TEST:\tEpoch: 200, Loss: 1.38674, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.19510, Accuracy: 92.53731\n",
      "TEST:\tEpoch: 210, Loss: 0.19510, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.03469, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 220, Loss: 0.03469, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.00841, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.00841, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.00413, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.00413, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00266, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00266, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00195, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00195, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00157, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00157, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00131, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00131, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00113, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00113, Accuracy: 87.50000\n",
      "Test Loss: 0.1648\n",
      "Epoch [10/10], Loss: 0.1645\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 2.12862, Accuracy: 70.14925\n",
      "TEST:\tEpoch: 300, Loss: 2.12862, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.45633, Accuracy: 80.59701\n",
      "TEST:\tEpoch: 310, Loss: 0.45633, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.10277, Accuracy: 98.50746\n",
      "TEST:\tEpoch: 320, Loss: 0.10277, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.05718, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.05718, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.02747, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.02747, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.01484, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.01484, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00986, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00986, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00750, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00750, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00590, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00590, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00489, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00489, Accuracy: 75.00000\n",
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1675\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 0.97875, Accuracy: 65.67164\n",
      "TEST:\tEpoch: 400, Loss: 0.97875, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.17362, Accuracy: 97.01493\n",
      "TEST:\tEpoch: 410, Loss: 0.17362, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.03734, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.03734, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.01141, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.01141, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00567, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00567, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00377, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00377, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00287, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00287, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00234, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00234, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00201, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00201, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00176, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00176, Accuracy: 75.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00158, Accuracy: 75.00000\n",
      "Test Loss: 0.1632\n",
      "Epoch [10/10], Loss: 0.1638\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 1.50699, Accuracy: 64.70588\n",
      "TEST:\tEpoch: 500, Loss: 1.50699, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 510, Loss: 0.26500, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 510, Loss: 0.26500, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 520, Loss: 0.07211, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 520, Loss: 0.07211, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 530, Loss: 0.03519, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.03519, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 540, Loss: 0.01620, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.01620, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00950, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00950, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00648, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00648, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00507, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00507, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00413, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00413, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00349, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00349, Accuracy: 71.42857\n",
      "Test Loss: 0.1654\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.60159, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 600, Loss: 1.60159, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 610, Loss: 0.47563, Accuracy: 75.00000\n",
      "TEST:\tEpoch: 610, Loss: 0.47563, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 620, Loss: 0.11764, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 620, Loss: 0.11764, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 630, Loss: 0.04940, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.04940, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 640, Loss: 0.02374, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.02374, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 650, Loss: 0.01308, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.01308, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00846, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00846, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00632, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00632, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00507, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00507, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00421, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00421, Accuracy: 57.14286\n",
      "Test Loss: 0.1653\n",
      "Epoch [10/10], Loss: 0.1652\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.22369, Accuracy: 60.29412\n",
      "TEST:\tEpoch: 700, Loss: 1.22369, Accuracy: 14.28571\n",
      "TRAIN:\tEpoch: 710, Loss: 0.28725, Accuracy: 91.17647\n",
      "TEST:\tEpoch: 710, Loss: 0.28725, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 720, Loss: 0.06150, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.06150, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 730, Loss: 0.01907, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.01907, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00835, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00835, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00483, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00483, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00341, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00341, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00268, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00268, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00222, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00222, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00190, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00190, Accuracy: 57.14286\n",
      "Test Loss: 0.1642\n",
      "Epoch [10/10], Loss: 0.1642\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.60096, Accuracy: 66.17647\n",
      "TEST:\tEpoch: 800, Loss: 1.60096, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 810, Loss: 0.39779, Accuracy: 85.29412\n",
      "TEST:\tEpoch: 810, Loss: 0.39779, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 820, Loss: 0.13162, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 820, Loss: 0.13162, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.05867, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.05867, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 840, Loss: 0.02381, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.02381, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 850, Loss: 0.01278, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.01278, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00708, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00708, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00330, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00330, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00182, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00182, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00126, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00126, Accuracy: 71.42857\n",
      "Test Loss: 0.1641\n",
      "Epoch [10/10], Loss: 0.1642\n",
      "(75, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 2.29896, Accuracy: 41.17647\n",
      "TEST:\tEpoch: 900, Loss: 2.29896, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 910, Loss: 0.33335, Accuracy: 89.70588\n",
      "TEST:\tEpoch: 910, Loss: 0.33335, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 920, Loss: 0.08120, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.08120, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 930, Loss: 0.03497, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.03497, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 940, Loss: 0.01475, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.01475, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00668, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00668, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00349, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00349, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00208, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00208, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00140, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00140, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00104, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00104, Accuracy: 85.71429\n",
      "(76, 21795)\n",
      "Test Loss: 0.0583\n",
      "Epoch [10/10], Loss: 0.0579\n",
      "(76, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:   0, Loss: 0.69418, Accuracy: 51.47059\n",
      "TEST:\tEpoch:   0, Loss: 0.69418, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.29306, Accuracy: 94.11765\n",
      "TEST:\tEpoch:  10, Loss: 0.29306, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.09892, Accuracy: 97.05882\n",
      "TEST:\tEpoch:  20, Loss: 0.09892, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.01366, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.01366, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00080, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00080, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00020, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00020, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00011, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00011, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00008, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00008, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00006, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00006, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00005, Accuracy: 87.50000\n",
      "Test Loss: 0.1610\n",
      "Epoch [10/10], Loss: 0.1607\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 2.69840, Accuracy: 51.47059\n",
      "TEST:\tEpoch: 100, Loss: 2.69840, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.49805, Accuracy: 75.00000\n",
      "TEST:\tEpoch: 110, Loss: 0.49805, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 120, Loss: 0.30401, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 120, Loss: 0.30401, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.17681, Accuracy: 94.11765\n",
      "TEST:\tEpoch: 130, Loss: 0.17681, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.10351, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 140, Loss: 0.10351, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.04663, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 150, Loss: 0.04663, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01637, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 160, Loss: 0.01637, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00965, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00965, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00615, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00615, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00307, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00307, Accuracy: 87.50000\n",
      "Test Loss: 0.1645\n",
      "Epoch [10/10], Loss: 0.1635\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 6.15362, Accuracy: 48.52941\n",
      "TEST:\tEpoch: 200, Loss: 6.15362, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.60568, Accuracy: 52.94118\n",
      "TEST:\tEpoch: 210, Loss: 0.60568, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 220, Loss: 0.51474, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 220, Loss: 0.51474, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.35222, Accuracy: 92.64706\n",
      "TEST:\tEpoch: 230, Loss: 0.35222, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.21249, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 240, Loss: 0.21249, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.11141, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 250, Loss: 0.11141, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.04864, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.04864, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.02113, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.02113, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.01036, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.01036, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00610, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00610, Accuracy: 100.00000\n",
      "Test Loss: 0.1658\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 3.27650, Accuracy: 48.52941\n",
      "TEST:\tEpoch: 300, Loss: 3.27650, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.79963, Accuracy: 50.00000\n",
      "TEST:\tEpoch: 310, Loss: 0.79963, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 320, Loss: 0.24670, Accuracy: 91.17647\n",
      "TEST:\tEpoch: 320, Loss: 0.24670, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.17024, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 330, Loss: 0.17024, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.11439, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 340, Loss: 0.11439, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.06815, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.06815, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.03939, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.03939, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.02350, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.02350, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.01478, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.01478, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.01006, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.01006, Accuracy: 100.00000\n",
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 2.09779, Accuracy: 48.52941\n",
      "TEST:\tEpoch: 400, Loss: 2.09779, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.29287, Accuracy: 86.76471\n",
      "TEST:\tEpoch: 410, Loss: 0.29287, Accuracy: 87.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 420, Loss: 0.13929, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 420, Loss: 0.13929, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.06062, Accuracy: 98.52941\n",
      "TEST:\tEpoch: 430, Loss: 0.06062, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.03327, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.03327, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.02107, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.02107, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.01531, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.01531, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.01250, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.01250, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.01037, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.01037, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00882, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00882, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00774, Accuracy: 100.00000\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 1.54016, Accuracy: 50.00000\n",
      "TEST:\tEpoch: 500, Loss: 1.54016, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.41743, Accuracy: 83.82353\n",
      "TEST:\tEpoch: 510, Loss: 0.41743, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.11688, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 520, Loss: 0.11688, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.05464, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.05464, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.02764, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.02764, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.01763, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.01763, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.01356, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.01356, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.01104, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.01104, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00928, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00928, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00806, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00806, Accuracy: 87.50000\n",
      "Test Loss: 0.1671\n",
      "Epoch [10/10], Loss: 0.1663\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.57402, Accuracy: 47.82609\n",
      "TEST:\tEpoch: 600, Loss: 1.57402, Accuracy: 28.57143\n",
      "TRAIN:\tEpoch: 610, Loss: 0.37779, Accuracy: 82.60870\n",
      "TEST:\tEpoch: 610, Loss: 0.37779, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 620, Loss: 0.12503, Accuracy: 97.10145\n",
      "TEST:\tEpoch: 620, Loss: 0.12503, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 630, Loss: 0.05382, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.05382, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 640, Loss: 0.02799, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.02799, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 650, Loss: 0.01793, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.01793, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 660, Loss: 0.01374, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.01374, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 670, Loss: 0.01108, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.01108, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00919, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00919, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00784, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00784, Accuracy: 71.42857\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.14237, Accuracy: 50.72464\n",
      "TEST:\tEpoch: 700, Loss: 1.14237, Accuracy: 57.14286\n",
      "TRAIN:\tEpoch: 710, Loss: 0.35877, Accuracy: 86.95652\n",
      "TEST:\tEpoch: 710, Loss: 0.35877, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 720, Loss: 0.07488, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.07488, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 730, Loss: 0.02732, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.02732, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.01252, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.01252, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00794, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00794, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00589, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00589, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00472, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00472, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00395, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00395, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00341, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00341, Accuracy: 85.71429\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.33180, Accuracy: 49.27536\n",
      "TEST:\tEpoch: 800, Loss: 1.33180, Accuracy: 42.85714\n",
      "TRAIN:\tEpoch: 810, Loss: 0.16944, Accuracy: 95.65217\n",
      "TEST:\tEpoch: 810, Loss: 0.16944, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 820, Loss: 0.02093, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.02093, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.00731, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.00731, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00417, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00417, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00287, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00287, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00215, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00215, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00158, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00158, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00111, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00111, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00079, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00079, Accuracy: 85.71429\n",
      "Test Loss: 0.1646\n",
      "Epoch [10/10], Loss: 0.1645\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 0.94185, Accuracy: 60.86957\n",
      "TEST:\tEpoch: 900, Loss: 0.94185, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 910, Loss: 0.06003, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 910, Loss: 0.06003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 920, Loss: 0.00862, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.00862, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 930, Loss: 0.00365, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.00365, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00235, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00235, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00161, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00161, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00132, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00132, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00114, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00114, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00101, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00101, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00091, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00091, Accuracy: 100.00000\n",
      "(39, 20387)\n",
      "Test Loss: 0.0728\n",
      "Epoch [10/10], Loss: 0.0664\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.66550, Accuracy: 71.42857\n",
      "TEST:\tEpoch:   0, Loss: 0.66550, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.30443, Accuracy: 88.57143\n",
      "TEST:\tEpoch:  10, Loss: 0.30443, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.15207, Accuracy: 94.28571\n",
      "TEST:\tEpoch:  20, Loss: 0.15207, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.04973, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.04973, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00151, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00151, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00051, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00051, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00016, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00016, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00008, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00008, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00006, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00006, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00005, Accuracy: 50.00000\n",
      "Test Loss: 0.1646\n",
      "Epoch [10/10], Loss: 0.1635\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 2.59541, Accuracy: 71.42857\n",
      "TEST:\tEpoch: 100, Loss: 2.59541, Accuracy: 25.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.25636, Accuracy: 88.57143\n",
      "TEST:\tEpoch: 110, Loss: 0.25636, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 120, Loss: 0.25473, Accuracy: 88.57143\n",
      "TEST:\tEpoch: 120, Loss: 0.25473, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 130, Loss: 0.18030, Accuracy: 88.57143\n",
      "TEST:\tEpoch: 130, Loss: 0.18030, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.12414, Accuracy: 97.14286\n",
      "TEST:\tEpoch: 140, Loss: 0.12414, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.05135, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.05135, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01197, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.01197, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00292, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00292, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00117, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00117, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00068, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00068, Accuracy: 75.00000\n",
      "Test Loss: 0.1641\n",
      "Epoch [10/10], Loss: 0.1626\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 3.13221, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 200, Loss: 3.13221, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.26538, Accuracy: 88.57143\n",
      "TEST:\tEpoch: 210, Loss: 0.26538, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.09035, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 220, Loss: 0.09035, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.02725, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.02725, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.01681, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.01681, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00830, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00830, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00522, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00522, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00352, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00352, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00262, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00262, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00207, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00207, Accuracy: 75.00000\n",
      "Test Loss: 0.1689\n",
      "Epoch [10/10], Loss: 0.1675\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 2.58835, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 300, Loss: 2.58835, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.19913, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 310, Loss: 0.19913, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.08699, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.08699, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.03655, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.03655, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.01914, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.01914, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00963, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00963, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00667, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00667, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00498, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00498, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00399, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00399, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00336, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00336, Accuracy: 50.00000\n",
      "Test Loss: 0.1701\n",
      "Epoch [10/10], Loss: 0.1683\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 1.43189, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 400, Loss: 1.43189, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.17351, Accuracy: 91.42857\n",
      "TEST:\tEpoch: 410, Loss: 0.17351, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.05585, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.05585, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.01655, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.01655, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00962, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00962, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00585, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00585, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00445, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00445, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00342, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00342, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00284, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00284, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00244, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00244, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00216, Accuracy: 100.00000\n",
      "Test Loss: 0.1680\n",
      "Epoch [10/10], Loss: 0.1671\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 0.89611, Accuracy: 62.85714\n",
      "TEST:\tEpoch: 500, Loss: 0.89611, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.12706, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 510, Loss: 0.12706, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.01816, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.01816, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.00566, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.00566, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.00298, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.00298, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00211, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00211, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00169, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00169, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00144, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00144, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00126, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00126, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00112, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00112, Accuracy: 100.00000\n",
      "Test Loss: 0.1700\n",
      "Epoch [10/10], Loss: 0.1703\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.24270, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 600, Loss: 1.24270, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 610, Loss: 0.07186, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 610, Loss: 0.07186, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 620, Loss: 0.01156, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 620, Loss: 0.01156, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 630, Loss: 0.00405, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.00405, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 640, Loss: 0.00261, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.00261, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 650, Loss: 0.00194, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.00194, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00158, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00158, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00140, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00140, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00126, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00126, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00115, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00115, Accuracy: 75.00000\n",
      "Test Loss: 0.1671\n",
      "Epoch [10/10], Loss: 0.1669\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.02863, Accuracy: 68.57143\n",
      "TEST:\tEpoch: 700, Loss: 2.02863, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 710, Loss: 0.31719, Accuracy: 94.28571\n",
      "TEST:\tEpoch: 710, Loss: 0.31719, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 720, Loss: 0.10849, Accuracy: 97.14286\n",
      "TEST:\tEpoch: 720, Loss: 0.10849, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 730, Loss: 0.02937, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.02937, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00727, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00727, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00333, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00333, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00191, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00191, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00135, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00135, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00105, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00105, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00087, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00087, Accuracy: 75.00000\n",
      "Test Loss: 0.1696\n",
      "Epoch [10/10], Loss: 0.1691\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 2.21741, Accuracy: 45.71429\n",
      "TEST:\tEpoch: 800, Loss: 2.21741, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 810, Loss: 0.38277, Accuracy: 74.28571\n",
      "TEST:\tEpoch: 810, Loss: 0.38277, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 820, Loss: 0.08548, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 820, Loss: 0.08548, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 830, Loss: 0.03138, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.03138, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 840, Loss: 0.00969, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.00969, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00370, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00370, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00202, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00202, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00139, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00139, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00107, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00107, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00088, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00088, Accuracy: 75.00000\n",
      "Test Loss: 0.1662\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "(39, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 3.87482, Accuracy: 69.44444\n",
      "TEST:\tEpoch: 900, Loss: 3.87482, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 910, Loss: 0.53631, Accuracy: 69.44444\n",
      "TEST:\tEpoch: 910, Loss: 0.53631, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 920, Loss: 0.30014, Accuracy: 69.44444\n",
      "TEST:\tEpoch: 920, Loss: 0.30014, Accuracy: 66.66667\n",
      "TRAIN:\tEpoch: 930, Loss: 0.11560, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.11560, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00275, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00275, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00013, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00013, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00003, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00001, Accuracy: 100.00000\n",
      "(114, 23715)\n",
      "Test Loss: 0.1052\n",
      "Epoch [10/10], Loss: 0.1050\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.71970, Accuracy: 41.17647\n",
      "TEST:\tEpoch:   0, Loss: 0.71970, Accuracy: 41.66667\n",
      "TRAIN:\tEpoch:  10, Loss: 0.14390, Accuracy: 97.05882\n",
      "TEST:\tEpoch:  10, Loss: 0.14390, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.00795, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  20, Loss: 0.00795, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.00018, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.00018, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00005, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00005, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00002, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00002, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00002, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00002, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00001, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00001, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00001, Accuracy: 100.00000\n",
      "Test Loss: 0.1614\n",
      "Epoch [10/10], Loss: 0.1602\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 3.78775, Accuracy: 58.82353\n",
      "TEST:\tEpoch: 100, Loss: 3.78775, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.06989, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 110, Loss: 0.06989, Accuracy: 100.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 120, Loss: 0.05112, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 120, Loss: 0.05112, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.05215, Accuracy: 98.03922\n",
      "TEST:\tEpoch: 130, Loss: 0.05215, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.02910, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 140, Loss: 0.02910, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.01704, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.01704, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.00832, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.00832, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00500, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00500, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00361, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00361, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00279, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00279, Accuracy: 100.00000\n",
      "Test Loss: 0.1626\n",
      "Epoch [10/10], Loss: 0.1624\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 1.99742, Accuracy: 58.82353\n",
      "TEST:\tEpoch: 200, Loss: 1.99742, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.17774, Accuracy: 94.11765\n",
      "TEST:\tEpoch: 210, Loss: 0.17774, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 220, Loss: 0.08732, Accuracy: 98.03922\n",
      "TEST:\tEpoch: 220, Loss: 0.08732, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.05449, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 230, Loss: 0.05449, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.04222, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 240, Loss: 0.04222, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 250, Loss: 0.02236, Accuracy: 99.01961\n",
      "TEST:\tEpoch: 250, Loss: 0.02236, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00815, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00815, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00388, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00388, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00237, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00237, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00167, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00167, Accuracy: 100.00000\n",
      "Test Loss: 0.1667\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 0.68410, Accuracy: 70.58824\n",
      "TEST:\tEpoch: 300, Loss: 0.68410, Accuracy: 58.33333\n",
      "TRAIN:\tEpoch: 310, Loss: 0.04421, Accuracy: 98.03922\n",
      "TEST:\tEpoch: 310, Loss: 0.04421, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 320, Loss: 0.00677, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.00677, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 330, Loss: 0.00268, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.00268, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 340, Loss: 0.00171, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.00171, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 350, Loss: 0.00129, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.00129, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00107, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00107, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00094, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00094, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00084, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00084, Accuracy: 91.66667\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00076, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00076, Accuracy: 91.66667\n",
      "Test Loss: 0.1647\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 3.15540, Accuracy: 59.22330\n",
      "TEST:\tEpoch: 400, Loss: 3.15540, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 410, Loss: 0.32365, Accuracy: 87.37864\n",
      "TEST:\tEpoch: 410, Loss: 0.32365, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 420, Loss: 0.18791, Accuracy: 95.14563\n",
      "TEST:\tEpoch: 420, Loss: 0.18791, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.04531, Accuracy: 99.02913\n",
      "TEST:\tEpoch: 430, Loss: 0.04531, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.00870, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.00870, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.00188, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.00188, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00077, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00077, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00050, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00050, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00038, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00038, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00033, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00033, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00029, Accuracy: 100.00000\n",
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 2.11544, Accuracy: 55.33981\n",
      "TEST:\tEpoch: 500, Loss: 2.11544, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 510, Loss: 0.12296, Accuracy: 96.11650\n",
      "TEST:\tEpoch: 510, Loss: 0.12296, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.02792, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.02792, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.01172, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.01172, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.00631, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.00631, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.00381, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.00381, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.00275, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.00275, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00212, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00212, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00175, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00175, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00147, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00147, Accuracy: 100.00000\n",
      "Test Loss: 0.1661\n",
      "Epoch [10/10], Loss: 0.1661\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 2.31610, Accuracy: 59.22330\n",
      "TEST:\tEpoch: 600, Loss: 2.31610, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 610, Loss: 0.57243, Accuracy: 70.87379\n",
      "TEST:\tEpoch: 610, Loss: 0.57243, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 620, Loss: 0.17159, Accuracy: 99.02913\n",
      "TEST:\tEpoch: 620, Loss: 0.17159, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 630, Loss: 0.08665, Accuracy: 99.02913\n",
      "TEST:\tEpoch: 630, Loss: 0.08665, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 640, Loss: 0.03675, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.03675, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 650, Loss: 0.01712, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.01712, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00946, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00946, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00600, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00600, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00440, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00440, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00351, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00351, Accuracy: 90.90909\n",
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1661\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.06375, Accuracy: 55.33981\n",
      "TEST:\tEpoch: 700, Loss: 1.06375, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 710, Loss: 0.27127, Accuracy: 89.32039\n",
      "TEST:\tEpoch: 710, Loss: 0.27127, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 720, Loss: 0.06839, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.06839, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 730, Loss: 0.02340, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.02340, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00996, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00996, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00545, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00545, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00282, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00282, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00122, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00122, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00065, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00065, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00043, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00043, Accuracy: 100.00000\n",
      "Test Loss: 0.1666\n",
      "Epoch [10/10], Loss: 0.1663\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 5.97096, Accuracy: 58.25243\n",
      "TEST:\tEpoch: 800, Loss: 5.97096, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 810, Loss: 0.68172, Accuracy: 58.25243\n",
      "TEST:\tEpoch: 810, Loss: 0.68172, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 820, Loss: 0.51865, Accuracy: 83.49515\n",
      "TEST:\tEpoch: 820, Loss: 0.51865, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 830, Loss: 0.31159, Accuracy: 97.08738\n",
      "TEST:\tEpoch: 830, Loss: 0.31159, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 840, Loss: 0.06514, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.06514, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00335, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00335, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00054, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00054, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00021, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00021, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00015, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00015, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00012, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00012, Accuracy: 90.90909\n",
      "Test Loss: 0.1651\n",
      "Epoch [10/10], Loss: 0.1652\n",
      "(114, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 4.74270, Accuracy: 58.25243\n",
      "TEST:\tEpoch: 900, Loss: 4.74270, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 910, Loss: 0.31616, Accuracy: 83.49515\n",
      "TEST:\tEpoch: 910, Loss: 0.31616, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 920, Loss: 0.06134, Accuracy: 99.02913\n",
      "TEST:\tEpoch: 920, Loss: 0.06134, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 930, Loss: 0.01981, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.01981, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 940, Loss: 0.00987, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.00987, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00590, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00590, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00375, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00375, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00243, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00243, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00171, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00171, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00130, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00130, Accuracy: 81.81818\n",
      "(76, 24031)\n",
      "Test Loss: 0.1315\n",
      "Epoch [10/10], Loss: 0.1284\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.66174, Accuracy: 67.64706\n",
      "TEST:\tEpoch:   0, Loss: 0.66174, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch:  10, Loss: 0.21502, Accuracy: 95.58824\n",
      "TEST:\tEpoch:  10, Loss: 0.21502, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  20, Loss: 0.00239, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  20, Loss: 0.00239, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.00003, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  30, Loss: 0.00003, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00000, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00000, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00000, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00000, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00000, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00000, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00000, Accuracy: 100.00000\n",
      "Test Loss: 0.1638\n",
      "Epoch [10/10], Loss: 0.1619\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 8.89752, Accuracy: 67.64706\n",
      "TEST:\tEpoch: 100, Loss: 8.89752, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 110, Loss: 0.28423, Accuracy: 83.82353\n",
      "TEST:\tEpoch: 110, Loss: 0.28423, Accuracy: 75.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 120, Loss: 0.34939, Accuracy: 67.64706\n",
      "TEST:\tEpoch: 120, Loss: 0.34939, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 130, Loss: 0.22675, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 130, Loss: 0.22675, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 140, Loss: 0.06836, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 140, Loss: 0.06836, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 150, Loss: 0.00595, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.00595, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 160, Loss: 0.00098, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.00098, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00029, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00029, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00013, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00013, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00007, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00007, Accuracy: 100.00000\n",
      "Test Loss: 0.1674\n",
      "Epoch [10/10], Loss: 0.1660\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 4.95121, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 200, Loss: 4.95121, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 210, Loss: 0.29632, Accuracy: 97.05882\n",
      "TEST:\tEpoch: 210, Loss: 0.29632, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 220, Loss: 0.20135, Accuracy: 95.58824\n",
      "TEST:\tEpoch: 220, Loss: 0.20135, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 230, Loss: 0.04384, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 230, Loss: 0.04384, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 240, Loss: 0.01236, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 240, Loss: 0.01236, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 250, Loss: 0.00430, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.00430, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 260, Loss: 0.00223, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.00223, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00151, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00151, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00118, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00118, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00099, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00099, Accuracy: 100.00000\n",
      "Test Loss: 0.1655\n",
      "Epoch [10/10], Loss: 0.1637\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 2.12367, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 300, Loss: 2.12367, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 310, Loss: 0.28728, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 310, Loss: 0.28728, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 320, Loss: 0.15435, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 320, Loss: 0.15435, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 330, Loss: 0.06485, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 330, Loss: 0.06485, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 340, Loss: 0.02342, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 340, Loss: 0.02342, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 350, Loss: 0.01073, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.01073, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 360, Loss: 0.00622, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.00622, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00438, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00438, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00338, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00338, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00277, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00277, Accuracy: 100.00000\n",
      "Test Loss: 0.1677\n",
      "Epoch [10/10], Loss: 0.1667\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 2.05629, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 400, Loss: 2.05629, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 410, Loss: 0.53152, Accuracy: 70.58824\n",
      "TEST:\tEpoch: 410, Loss: 0.53152, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 420, Loss: 0.29572, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 420, Loss: 0.29572, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 430, Loss: 0.20057, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 430, Loss: 0.20057, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 440, Loss: 0.09091, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 440, Loss: 0.09091, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 450, Loss: 0.02944, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.02944, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00895, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00895, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00332, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00332, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00154, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00154, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00088, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00088, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 499, Loss: 0.00060, Accuracy: 100.00000\n",
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 2.24069, Accuracy: 69.11765\n",
      "TEST:\tEpoch: 500, Loss: 2.24069, Accuracy: 62.50000\n",
      "TRAIN:\tEpoch: 510, Loss: 0.42377, Accuracy: 80.88235\n",
      "TEST:\tEpoch: 510, Loss: 0.42377, Accuracy: 75.00000\n",
      "TRAIN:\tEpoch: 520, Loss: 0.21326, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 520, Loss: 0.21326, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 530, Loss: 0.12085, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 530, Loss: 0.12085, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 540, Loss: 0.05075, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 540, Loss: 0.05075, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 550, Loss: 0.02098, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 550, Loss: 0.02098, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 560, Loss: 0.01055, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 560, Loss: 0.01055, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 570, Loss: 0.00649, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 570, Loss: 0.00649, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 580, Loss: 0.00461, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 580, Loss: 0.00461, Accuracy: 87.50000\n",
      "TRAIN:\tEpoch: 590, Loss: 0.00358, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 590, Loss: 0.00358, Accuracy: 87.50000\n",
      "Test Loss: 0.1670\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.86538, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 600, Loss: 1.86538, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 610, Loss: 0.62948, Accuracy: 65.21739\n",
      "TEST:\tEpoch: 610, Loss: 0.62948, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 620, Loss: 0.27275, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 620, Loss: 0.27275, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 630, Loss: 0.18226, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 630, Loss: 0.18226, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 640, Loss: 0.07229, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 640, Loss: 0.07229, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 650, Loss: 0.01413, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 650, Loss: 0.01413, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 660, Loss: 0.00184, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.00184, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 670, Loss: 0.00038, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.00038, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 680, Loss: 0.00015, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.00015, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 690, Loss: 0.00009, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.00009, Accuracy: 100.00000\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 2.37283, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 700, Loss: 2.37283, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 710, Loss: 0.47161, Accuracy: 76.81159\n",
      "TEST:\tEpoch: 710, Loss: 0.47161, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 720, Loss: 0.04284, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 720, Loss: 0.04284, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 730, Loss: 0.01061, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 730, Loss: 0.01061, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 740, Loss: 0.00589, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.00589, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 750, Loss: 0.00226, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.00226, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 760, Loss: 0.00175, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.00175, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 770, Loss: 0.00141, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.00141, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 780, Loss: 0.00115, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.00115, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 790, Loss: 0.00098, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.00098, Accuracy: 100.00000\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1674\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 2.26847, Accuracy: 68.11594\n",
      "TEST:\tEpoch: 800, Loss: 2.26847, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 810, Loss: 0.39538, Accuracy: 79.71014\n",
      "TEST:\tEpoch: 810, Loss: 0.39538, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 820, Loss: 0.15629, Accuracy: 95.65217\n",
      "TEST:\tEpoch: 820, Loss: 0.15629, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 830, Loss: 0.03635, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.03635, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 840, Loss: 0.01826, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.01826, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 850, Loss: 0.00897, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.00897, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 860, Loss: 0.00621, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.00621, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 870, Loss: 0.00441, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.00441, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 880, Loss: 0.00349, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.00349, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 890, Loss: 0.00290, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.00290, Accuracy: 71.42857\n",
      "Test Loss: 0.1642\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "(76, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.43815, Accuracy: 66.66667\n",
      "TEST:\tEpoch: 900, Loss: 1.43815, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 910, Loss: 0.33358, Accuracy: 85.50725\n",
      "TEST:\tEpoch: 910, Loss: 0.33358, Accuracy: 71.42857\n",
      "TRAIN:\tEpoch: 920, Loss: 0.09017, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 920, Loss: 0.09017, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 930, Loss: 0.03161, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.03161, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.01403, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.01403, Accuracy: 85.71429\n",
      "TRAIN:\tEpoch: 950, Loss: 0.00808, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.00808, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.00578, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.00578, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.00459, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.00459, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00381, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00381, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00329, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00329, Accuracy: 100.00000\n",
      "(108, 20568)\n",
      "Test Loss: 0.0548\n",
      "Epoch [10/10], Loss: 0.0543\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch:   0, Loss: 0.69998, Accuracy: 43.29897\n",
      "TEST:\tEpoch:   0, Loss: 0.69998, Accuracy: 45.45455\n",
      "TRAIN:\tEpoch:  10, Loss: 0.49959, Accuracy: 86.59794\n",
      "TEST:\tEpoch:  10, Loss: 0.49959, Accuracy: 90.90909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch:  20, Loss: 0.21180, Accuracy: 90.72165\n",
      "TEST:\tEpoch:  20, Loss: 0.21180, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  30, Loss: 0.06535, Accuracy: 95.87629\n",
      "TEST:\tEpoch:  30, Loss: 0.06535, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  40, Loss: 0.00695, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  40, Loss: 0.00695, Accuracy: 100.00000\n",
      "TRAIN:\tEpoch:  50, Loss: 0.00149, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  50, Loss: 0.00149, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  60, Loss: 0.00041, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  60, Loss: 0.00041, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  70, Loss: 0.00023, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  70, Loss: 0.00023, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  80, Loss: 0.00017, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  80, Loss: 0.00017, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch:  90, Loss: 0.00014, Accuracy: 100.00000\n",
      "TEST:\tEpoch:  90, Loss: 0.00014, Accuracy: 90.90909\n",
      "Test Loss: 0.1578\n",
      "Epoch [10/10], Loss: 0.1576\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 100, Loss: 1.45141, Accuracy: 40.20619\n",
      "TEST:\tEpoch: 100, Loss: 1.45141, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 110, Loss: 0.30845, Accuracy: 83.50515\n",
      "TEST:\tEpoch: 110, Loss: 0.30845, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 120, Loss: 0.18226, Accuracy: 93.81443\n",
      "TEST:\tEpoch: 120, Loss: 0.18226, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 130, Loss: 0.10827, Accuracy: 95.87629\n",
      "TEST:\tEpoch: 130, Loss: 0.10827, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 140, Loss: 0.06289, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 140, Loss: 0.06289, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 150, Loss: 0.02920, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 150, Loss: 0.02920, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 160, Loss: 0.01469, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 160, Loss: 0.01469, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 170, Loss: 0.00769, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 170, Loss: 0.00769, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 180, Loss: 0.00446, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 180, Loss: 0.00446, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 190, Loss: 0.00286, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 190, Loss: 0.00286, Accuracy: 81.81818\n",
      "Test Loss: 0.1600\n",
      "Epoch [10/10], Loss: 0.1603\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 200, Loss: 2.10592, Accuracy: 60.82474\n",
      "TEST:\tEpoch: 200, Loss: 2.10592, Accuracy: 45.45455\n",
      "TRAIN:\tEpoch: 210, Loss: 0.41049, Accuracy: 83.50515\n",
      "TEST:\tEpoch: 210, Loss: 0.41049, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 220, Loss: 0.19252, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 220, Loss: 0.19252, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 230, Loss: 0.11914, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 230, Loss: 0.11914, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 240, Loss: 0.06037, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 240, Loss: 0.06037, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 250, Loss: 0.02466, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 250, Loss: 0.02466, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 260, Loss: 0.01204, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 260, Loss: 0.01204, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 270, Loss: 0.00698, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 270, Loss: 0.00698, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 280, Loss: 0.00446, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 280, Loss: 0.00446, Accuracy: 90.90909\n",
      "TRAIN:\tEpoch: 290, Loss: 0.00316, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 290, Loss: 0.00316, Accuracy: 81.81818\n",
      "Test Loss: 0.1642\n",
      "Epoch [10/10], Loss: 0.1645\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 300, Loss: 2.10371, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 300, Loss: 2.10371, Accuracy: 45.45455\n",
      "TRAIN:\tEpoch: 310, Loss: 0.44851, Accuracy: 83.50515\n",
      "TEST:\tEpoch: 310, Loss: 0.44851, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 320, Loss: 0.26163, Accuracy: 87.62887\n",
      "TEST:\tEpoch: 320, Loss: 0.26163, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 330, Loss: 0.14205, Accuracy: 94.84536\n",
      "TEST:\tEpoch: 330, Loss: 0.14205, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 340, Loss: 0.06789, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 340, Loss: 0.06789, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 350, Loss: 0.02690, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 350, Loss: 0.02690, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 360, Loss: 0.01009, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 360, Loss: 0.01009, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 370, Loss: 0.00475, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 370, Loss: 0.00475, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 380, Loss: 0.00267, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 380, Loss: 0.00267, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 390, Loss: 0.00182, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 390, Loss: 0.00182, Accuracy: 81.81818\n",
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 400, Loss: 3.78117, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 400, Loss: 3.78117, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 410, Loss: 0.62895, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 410, Loss: 0.62895, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 420, Loss: 0.60194, Accuracy: 83.50515\n",
      "TEST:\tEpoch: 420, Loss: 0.60194, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 430, Loss: 0.43398, Accuracy: 89.69072\n",
      "TEST:\tEpoch: 430, Loss: 0.43398, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 440, Loss: 0.18995, Accuracy: 93.81443\n",
      "TEST:\tEpoch: 440, Loss: 0.18995, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 450, Loss: 0.03977, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 450, Loss: 0.03977, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 460, Loss: 0.00462, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 460, Loss: 0.00462, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 470, Loss: 0.00106, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 470, Loss: 0.00106, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 480, Loss: 0.00045, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 480, Loss: 0.00045, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 490, Loss: 0.00027, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 490, Loss: 0.00027, Accuracy: 63.63636\n",
      "TEST:\tEpoch: 499, Loss: 0.00020, Accuracy: 63.63636\n",
      "Test Loss: 0.1666\n",
      "Epoch [10/10], Loss: 0.1665\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 500, Loss: 4.14412, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 500, Loss: 4.14412, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 510, Loss: 0.63182, Accuracy: 57.73196\n",
      "TEST:\tEpoch: 510, Loss: 0.63182, Accuracy: 63.63636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\tEpoch: 520, Loss: 0.60969, Accuracy: 62.88660\n",
      "TEST:\tEpoch: 520, Loss: 0.60969, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 530, Loss: 0.59126, Accuracy: 57.73196\n",
      "TEST:\tEpoch: 530, Loss: 0.59126, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 540, Loss: 0.55299, Accuracy: 83.50515\n",
      "TEST:\tEpoch: 540, Loss: 0.55299, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 550, Loss: 0.49284, Accuracy: 78.35052\n",
      "TEST:\tEpoch: 550, Loss: 0.49284, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 560, Loss: 0.41285, Accuracy: 91.75258\n",
      "TEST:\tEpoch: 560, Loss: 0.41285, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 570, Loss: 0.31802, Accuracy: 95.87629\n",
      "TEST:\tEpoch: 570, Loss: 0.31802, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 580, Loss: 0.22038, Accuracy: 96.90722\n",
      "TEST:\tEpoch: 580, Loss: 0.22038, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 590, Loss: 0.13554, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 590, Loss: 0.13554, Accuracy: 72.72727\n",
      "Test Loss: 0.1652\n",
      "Epoch [10/10], Loss: 0.1648\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 600, Loss: 1.38557, Accuracy: 56.70103\n",
      "TEST:\tEpoch: 600, Loss: 1.38557, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 610, Loss: 0.62423, Accuracy: 65.97938\n",
      "TEST:\tEpoch: 610, Loss: 0.62423, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 620, Loss: 0.33523, Accuracy: 88.65979\n",
      "TEST:\tEpoch: 620, Loss: 0.33523, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 630, Loss: 0.21861, Accuracy: 92.78351\n",
      "TEST:\tEpoch: 630, Loss: 0.21861, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 640, Loss: 0.12792, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 640, Loss: 0.12792, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 650, Loss: 0.07498, Accuracy: 98.96907\n",
      "TEST:\tEpoch: 650, Loss: 0.07498, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 660, Loss: 0.04442, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 660, Loss: 0.04442, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 670, Loss: 0.02798, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 670, Loss: 0.02798, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 680, Loss: 0.01820, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 680, Loss: 0.01820, Accuracy: 81.81818\n",
      "TRAIN:\tEpoch: 690, Loss: 0.01288, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 690, Loss: 0.01288, Accuracy: 81.81818\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 700, Loss: 1.82456, Accuracy: 53.60825\n",
      "TEST:\tEpoch: 700, Loss: 1.82456, Accuracy: 72.72727\n",
      "TRAIN:\tEpoch: 710, Loss: 0.70301, Accuracy: 64.94845\n",
      "TEST:\tEpoch: 710, Loss: 0.70301, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 720, Loss: 0.26828, Accuracy: 89.69072\n",
      "TEST:\tEpoch: 720, Loss: 0.26828, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 730, Loss: 0.14100, Accuracy: 97.93814\n",
      "TEST:\tEpoch: 730, Loss: 0.14100, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 740, Loss: 0.07545, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 740, Loss: 0.07545, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 750, Loss: 0.04591, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 750, Loss: 0.04591, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 760, Loss: 0.02968, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 760, Loss: 0.02968, Accuracy: 63.63636\n",
      "TRAIN:\tEpoch: 770, Loss: 0.02071, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 770, Loss: 0.02071, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 780, Loss: 0.01553, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 780, Loss: 0.01553, Accuracy: 54.54545\n",
      "TRAIN:\tEpoch: 790, Loss: 0.01226, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 790, Loss: 0.01226, Accuracy: 54.54545\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1653\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 800, Loss: 1.48999, Accuracy: 53.06122\n",
      "TEST:\tEpoch: 800, Loss: 1.48999, Accuracy: 40.00000\n",
      "TRAIN:\tEpoch: 810, Loss: 0.53169, Accuracy: 71.42857\n",
      "TEST:\tEpoch: 810, Loss: 0.53169, Accuracy: 20.00000\n",
      "TRAIN:\tEpoch: 820, Loss: 0.21479, Accuracy: 94.89796\n",
      "TEST:\tEpoch: 820, Loss: 0.21479, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 830, Loss: 0.10015, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 830, Loss: 0.10015, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 840, Loss: 0.05475, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 840, Loss: 0.05475, Accuracy: 60.00000\n",
      "TRAIN:\tEpoch: 850, Loss: 0.03268, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 850, Loss: 0.03268, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 860, Loss: 0.02203, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 860, Loss: 0.02203, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 870, Loss: 0.01613, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 870, Loss: 0.01613, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 880, Loss: 0.01248, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 880, Loss: 0.01248, Accuracy: 50.00000\n",
      "TRAIN:\tEpoch: 890, Loss: 0.01010, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 890, Loss: 0.01010, Accuracy: 50.00000\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "(108, 2000)\n",
      "TRAIN:\tEpoch: 900, Loss: 1.29524, Accuracy: 51.02041\n",
      "TEST:\tEpoch: 900, Loss: 1.29524, Accuracy: 70.00000\n",
      "TRAIN:\tEpoch: 910, Loss: 0.47302, Accuracy: 76.53061\n",
      "TEST:\tEpoch: 910, Loss: 0.47302, Accuracy: 70.00000\n",
      "TRAIN:\tEpoch: 920, Loss: 0.13891, Accuracy: 96.93878\n",
      "TEST:\tEpoch: 920, Loss: 0.13891, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 930, Loss: 0.06075, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 930, Loss: 0.06075, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 940, Loss: 0.03125, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 940, Loss: 0.03125, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 950, Loss: 0.02020, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 950, Loss: 0.02020, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 960, Loss: 0.01428, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 960, Loss: 0.01428, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 970, Loss: 0.01097, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 970, Loss: 0.01097, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 980, Loss: 0.00888, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 980, Loss: 0.00888, Accuracy: 80.00000\n",
      "TRAIN:\tEpoch: 990, Loss: 0.00743, Accuracy: 100.00000\n",
      "TEST:\tEpoch: 990, Loss: 0.00743, Accuracy: 80.00000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datas)):\n",
    "    print(datas[i].shape)\n",
    "    model_autoencoder_multilayer_perceptron = MultilayerPerceptron(input_size=2000, output_size=2)\n",
    "    model_autoencoder_multilayer_perceptron, train_accs_autoencoder_multilayer_perceptron, train_losses_autoencoder_multilayer_perceptron, train_points_autoencoder_multilayer_perceptron, train_prec_autoencoder_multilayer_perceptron, train_recall_autoencoder_multilayer_perceptron, train_f1_autoencoder_multilayer_perceptron, test_accs_autoencoder_multilayer_perceptron, test_losses_autoencoder_multilayer_perceptron, test_points_autoencoder_multilayer_perceptron, test_prec_autoencoder_multilayer_perceptron, test_recall_autoencoder_multilayer_perceptron, test_f1_autoencoder_multilayer_perceptron = prepare_train_k_fold_with_normalization_and_imputation(model_autoencoder_multilayer_perceptron, datas[i].values, labels[i]['Labels'].values, reshape_size=datas[i].shape[1], n_epochs=100)\n",
    "    train_accs_mlp[names[i]] = train_accs_autoencoder_multilayer_perceptron\n",
    "    train_losses_mlp[names[i]] = train_losses_autoencoder_multilayer_perceptron\n",
    "    train_points_mlp[names[i]] = train_points_autoencoder_multilayer_perceptron\n",
    "    train_precs_mlp[names[i]] = train_prec_autoencoder_multilayer_perceptron\n",
    "    train_recalls_mlp[names[i]] = train_recall_autoencoder_multilayer_perceptron\n",
    "    train_f1s_mlp[names[i]] = train_f1_autoencoder_multilayer_perceptron\n",
    "    test_accs_mlp[names[i]] = test_accs_autoencoder_multilayer_perceptron\n",
    "    test_losses_mlp[names[i]] = test_losses_autoencoder_multilayer_perceptron\n",
    "    test_points_mlp[names[i]] = test_points_autoencoder_multilayer_perceptron\n",
    "    test_precs_mlp[names[i]] = test_prec_autoencoder_multilayer_perceptron\n",
    "    test_recalls_mlp[names[i]] = test_recall_autoencoder_multilayer_perceptron\n",
    "    test_f1s_mlp[names[i]] = test_f1_autoencoder_multilayer_perceptron\n",
    "    models_mlp[names[i]] = model_autoencoder_multilayer_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def train_random_forest(model, X, y, n_epoch=100):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    train_precisions = []\n",
    "    train_recalls = []\n",
    "    train_accuracies = []\n",
    "    train_f1_scores = []\n",
    "\n",
    "    test_precisions = []\n",
    "    test_recalls = []\n",
    "    test_accuracies = []\n",
    "    test_f1_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X = pd.DataFrame(missing_value_imputation(X))\n",
    "        X = normalize_data(X)\n",
    "        X = ((pd.DataFrame(feature_extraction(X).detach().numpy())))\n",
    "        # X_train, X_test = X[train_index], X[test_index]\n",
    "        # y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        X_train, y_train = X.iloc[train_index], y[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "        train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "\n",
    "        test_precision = precision_score(y_test, y_pred_test, average='weighted')\n",
    "        test_recall = recall_score(y_test, y_pred_test, average='weighted')\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        test_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        train_precisions.append(train_precision)\n",
    "        train_recalls.append(train_recall)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_f1_scores.append(train_f1)\n",
    "\n",
    "        test_precisions.append(test_precision)\n",
    "        test_recalls.append(test_recall)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        test_f1_scores.append(test_f1)\n",
    "        print(train_f1, test_f1)\n",
    "    return model, train_precisions, train_recalls, train_accuracies, train_f1_scores, test_precisions, test_recalls, test_accuracies, test_f1_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 28303)\n",
      "Test Loss: 0.0484\n",
      "Epoch [10/10], Loss: 0.0518\n",
      "1.0 0.8589743589743589\n",
      "Test Loss: 0.1550\n",
      "Epoch [10/10], Loss: 0.1561\n",
      "1.0 0.8589743589743589\n",
      "Test Loss: 0.1614\n",
      "Epoch [10/10], Loss: 0.1629\n",
      "1.0 0.4807692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1677\n",
      "Epoch [10/10], Loss: 0.1683\n",
      "1.0 0.41666666666666663\n",
      "Test Loss: 0.1647\n",
      "Epoch [10/10], Loss: 0.1649\n",
      "1.0 0.4807692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1661\n",
      "Epoch [10/10], Loss: 0.1655\n",
      "1.0 0.5952380952380951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "1.0 0.5952380952380951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1670\n",
      "Epoch [10/10], Loss: 0.1671\n",
      "1.0 0.5952380952380951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1658\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "1.0 0.5952380952380951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1670\n",
      "Epoch [10/10], Loss: 0.1673\n",
      "1.0 0.5952380952380951\n",
      "(76, 21795)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0584\n",
      "Epoch [10/10], Loss: 0.0579\n",
      "1.0 0.873015873015873\n",
      "Test Loss: 0.1580\n",
      "Epoch [10/10], Loss: 0.1569\n",
      "1.0 1.0\n",
      "Test Loss: 0.1637\n",
      "Epoch [10/10], Loss: 0.1634\n",
      "1.0 0.873015873015873\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1647\n",
      "1.0 0.873015873015873\n",
      "Test Loss: 0.1656\n",
      "Epoch [10/10], Loss: 0.1648\n",
      "1.0 1.0\n",
      "Test Loss: 0.1659\n",
      "Epoch [10/10], Loss: 0.1655\n",
      "1.0 0.7333333333333334\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1651\n",
      "1.0 1.0\n",
      "Test Loss: 0.1661\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "1.0 0.8507936507936508\n",
      "Test Loss: 0.1647\n",
      "Epoch [10/10], Loss: 0.1651\n",
      "1.0 0.8571428571428571\n",
      "Test Loss: 0.1644\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "1.0 0.7023809523809523\n",
      "(39, 20387)\n",
      "Test Loss: 0.0729\n",
      "Epoch [10/10], Loss: 0.0665\n",
      "1.0 0.5\n",
      "Test Loss: 0.1644\n",
      "Epoch [10/10], Loss: 0.1622\n",
      "1.0 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1673\n",
      "Epoch [10/10], Loss: 0.1669\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1680\n",
      "Epoch [10/10], Loss: 0.1672\n",
      "1.0 1.0\n",
      "Test Loss: 0.1691\n",
      "Epoch [10/10], Loss: 0.1678\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1648\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1681\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1682\n",
      "Epoch [10/10], Loss: 0.1667\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1698\n",
      "Epoch [10/10], Loss: 0.1690\n",
      "1.0 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1676\n",
      "Epoch [10/10], Loss: 0.1672\n",
      "1.0 0.5333333333333333\n",
      "(114, 23715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1054\n",
      "Epoch [10/10], Loss: 0.1053\n",
      "1.0 1.0\n",
      "Test Loss: 0.1587\n",
      "Epoch [10/10], Loss: 0.1585\n",
      "1.0 1.0\n",
      "Test Loss: 0.1642\n",
      "Epoch [10/10], Loss: 0.1633\n",
      "1.0 1.0\n",
      "Test Loss: 0.1641\n",
      "Epoch [10/10], Loss: 0.1638\n",
      "1.0 0.9148148148148149\n",
      "Test Loss: 0.1651\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "1.0 0.9075369075369075\n",
      "Test Loss: 0.1666\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "1.0 0.9075369075369075\n",
      "Test Loss: 0.1660\n",
      "Epoch [10/10], Loss: 0.1654\n",
      "1.0 0.9075369075369075\n",
      "Test Loss: 0.1673\n",
      "Epoch [10/10], Loss: 0.1671\n",
      "1.0 1.0\n",
      "Test Loss: 0.1652\n",
      "Epoch [10/10], Loss: 0.1652\n",
      "1.0 0.7168831168831169\n",
      "Test Loss: 0.1652\n",
      "Epoch [10/10], Loss: 0.1646\n",
      "1.0 0.9056277056277057\n",
      "(76, 24031)\n",
      "Test Loss: 0.1315\n",
      "Epoch [10/10], Loss: 0.1284\n",
      "1.0 1.0\n",
      "Test Loss: 0.1663\n",
      "Epoch [10/10], Loss: 0.1646\n",
      "1.0 1.0\n",
      "Test Loss: 0.1657\n",
      "Epoch [10/10], Loss: 0.1638\n",
      "1.0 1.0\n",
      "Test Loss: 0.1656\n",
      "Epoch [10/10], Loss: 0.1646\n",
      "1.0 1.0\n",
      "Test Loss: 0.1683\n",
      "Epoch [10/10], Loss: 0.1673\n",
      "1.0 0.8681818181818182\n",
      "Test Loss: 0.1654\n",
      "Epoch [10/10], Loss: 0.1650\n",
      "1.0 1.0\n",
      "Test Loss: 0.1664\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "1.0 1.0\n",
      "Test Loss: 0.1658\n",
      "Epoch [10/10], Loss: 0.1656\n",
      "1.0 0.8398268398268397\n",
      "Test Loss: 0.1671\n",
      "Epoch [10/10], Loss: 0.1668\n",
      "1.0 0.5952380952380951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1656\n",
      "Epoch [10/10], Loss: 0.1659\n",
      "1.0 0.8398268398268397\n",
      "(108, 20568)\n",
      "Test Loss: 0.0548\n",
      "Epoch [10/10], Loss: 0.0543\n",
      "1.0 0.8181818181818182\n",
      "Test Loss: 0.1554\n",
      "Epoch [10/10], Loss: 0.1557\n",
      "1.0 0.9090909090909091\n",
      "Test Loss: 0.1624\n",
      "Epoch [10/10], Loss: 0.1619\n",
      "1.0 0.8181818181818182\n",
      "Test Loss: 0.1647\n",
      "Epoch [10/10], Loss: 0.1653\n",
      "1.0 0.4935064935064935\n",
      "Test Loss: 0.1628\n",
      "Epoch [10/10], Loss: 0.1629\n",
      "1.0 0.9075369075369075\n",
      "Test Loss: 0.1650\n",
      "Epoch [10/10], Loss: 0.1655\n",
      "1.0 0.6961038961038962\n",
      "Test Loss: 0.1665\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "1.0 0.8181818181818182\n",
      "Test Loss: 0.1664\n",
      "Epoch [10/10], Loss: 0.1664\n",
      "1.0 0.7992424242424243\n",
      "Test Loss: 0.1652\n",
      "Epoch [10/10], Loss: 0.1644\n",
      "1.0 0.8967032967032967\n",
      "Test Loss: 0.1669\n",
      "Epoch [10/10], Loss: 0.1662\n",
      "1.0 0.4499999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_accs_rf = {}\n",
    "train_prec_rf = {}\n",
    "train_recall_rf = {}\n",
    "train_f1_rf = {}\n",
    "test_accs_rf = {}\n",
    "test_prec_rf = {}\n",
    "test_recall_rf = {}\n",
    "test_f1_rf = {}\n",
    "models_rf = {}\n",
    "\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    print(datas[i].shape)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    model_rf, train_precision_rf, train_recalls_rf, train_accuracies_rf, train_f1_scores_rf, test_precisions_rf, test_recalls_rf, test_accuracies_rf, test_f1_scores_rf = train_random_forest(model=rf_model, X=datas[i].values, y=labels[i]['Labels'].values)\n",
    "    \n",
    "    train_accs_rf[names[i]] = train_accuracies_rf\n",
    "    train_prec_rf[names[i]] = train_precision_rf\n",
    "    train_recall_rf[names[i]] = train_recalls_rf\n",
    "    train_f1_rf[names[i]] = train_f1_scores_rf\n",
    "    test_accs_rf[names[i]] = test_accuracies_rf\n",
    "    test_prec_rf[names[i]] = test_precisions_rf\n",
    "    test_recall_rf[names[i]] = test_recalls_rf\n",
    "    test_f1_rf[names[i]] = test_f1_scores_rf\n",
    "    models_rf[names[i]] = model_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_rf = {}\n",
    "recall_scores_rf = {}\n",
    "accuracy_scores_rf = {}\n",
    "f1_scores_rf = {}\n",
    "\n",
    "precision_scores_lr = {}\n",
    "recall_scores_lr = {}\n",
    "accuracy_scores_lr = {}\n",
    "f1_scores_lr = {}\n",
    "\n",
    "precision_scores_mlp = {}\n",
    "recall_scores_mlp = {}\n",
    "accuracy_scores_mlp = {}\n",
    "f1_scores_mlp = {}\n",
    "\n",
    "precision_scores_cnn = {}\n",
    "recall_scores_cnn = {}\n",
    "accuracy_scores_cnn = {}\n",
    "f1_scores_cnn = {}\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    precision_scores_rf[name] = np.mean(test_prec_rf[name] + train_prec_rf[name]) \n",
    "    recall_scores_rf[name] = np.mean(test_recall_rf[name] + train_recall_rf[name]) \n",
    "    accuracy_scores_rf[name] = np.mean(test_accs_rf[name] + train_accs_rf[name]) \n",
    "    f1_scores_rf[name] = np.mean(test_f1_rf[name] + train_f1_rf[name]) \n",
    "\n",
    "\n",
    "    precision_scores_lr[name] = np.mean(test_precs_logistic_regression[name] + train_precs_logistic_regression[name]) \n",
    "    recall_scores_lr[name] = np.mean(test_recalls_logistic_regression[name] + train_recalls_logistic_regression[name]) \n",
    "    accuracy_scores_lr[name] = np.mean(test_accs_logistic_regression[name] + train_accs_logistic_regression[name]) * 0.01\n",
    "    f1_scores_lr[name] = np.mean(test_f1s_logistic_regression[name] + train_f1s_logistic_regression[name]) \n",
    "\n",
    "\n",
    "    precision_scores_mlp[name] = np.mean(test_precs_mlp[name] + train_precs_mlp[name]) \n",
    "    recall_scores_mlp[name] = np.mean(test_recalls_mlp[name] + train_recalls_mlp[name]) \n",
    "    accuracy_scores_mlp[name] = np.mean(test_accs_mlp[name] + train_accs_mlp[name]) * 0.01\n",
    "    f1_scores_mlp[name] = np.mean(test_f1s_mlp[name] + train_f1s_mlp[name]) \n",
    "\n",
    "\n",
    "\n",
    "    precision_scores_cnn[name] = np.mean(test_precs_cnn[name] + train_precs_cnn[name]) \n",
    "    recall_scores_cnn[name] = np.mean(test_recalls_cnn[name] + train_recalls_cnn[name]) \n",
    "    accuracy_scores_cnn[name] = np.mean(test_accs_cnn[name] + train_accs_cnn[name]) * 0.01\n",
    "    f1_scores_cnn[name] = np.mean(test_f1s_cnn[name] + train_f1s_cnn[name]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model_rf(model, data, labels):\n",
    "    predicted = model.predict(data)\n",
    "    precision = precision_score(labels, predicted, average='weighted')\n",
    "    recall = recall_score(labels, predicted, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predicted)\n",
    "    f1 = f1_score(labels, predicted)\n",
    "    return precision, recall, accuracy, f1\n",
    "    \n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "for i, name in enumerate(names):\n",
    "    # model = models_rf[name]\n",
    "\n",
    "    # X_train = pd.DataFrame(missing_value_imputation(datas[i]))\n",
    "    # X_train = normalize_data(X_train)\n",
    "    # X_train = (pd.DataFrame(feature_extraction(X_train).detach().numpy()))\n",
    "    \n",
    "    # data = X_train.values\n",
    "    # label = labels[i].values\n",
    "\n",
    "    # precision, recall, accuracy, f1 = evaluate_model_rf(model, data, label)\n",
    "    precision_scores.append(precision_scores_rf[name])\n",
    "    recall_scores.append(recall_scores_rf[name])\n",
    "    accuracy_scores.append(accuracy_scores_rf[name])\n",
    "    f1_scores.append(f1_scores_rf[name])\n",
    "\n",
    "x = np.arange(len(names))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width - width/2, precision_scores, width, label='Precision')\n",
    "rects2 = ax.bar(x - width/2, recall_scores, width, label='Recall')\n",
    "rects3 = ax.bar(x + width/2, accuracy_scores, width, label='Accuracy')\n",
    "rects4 = ax.bar(x + width + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_title('RF')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('%.2f' % height,\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scores_plot_without_eval(precisions, recalls, accuracies, f1s, title):\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    for i, name in enumerate(names):\n",
    "\n",
    "        precision_scores.append(precisions[name])\n",
    "        recall_scores.append(recalls[name])\n",
    "        accuracy_scores.append(accuracies[name])\n",
    "        f1_scores.append(f1s[name])\n",
    "\n",
    "    x = np.arange(len(names))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    rects1 = ax.bar(x - width - width/2, precision_scores, width, label='Precision')\n",
    "    rects2 = ax.bar(x - width/2, recall_scores, width, label='Recall')\n",
    "    rects3 = ax.bar(x + width/2, accuracy_scores, width, label='Accuracy')\n",
    "    rects4 = ax.bar(x + width + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "    ax.set_xlabel('Datasets')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('%.2f' % height,\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_scores_plot_without_eval(precision_scores_lr, recall_scores_lr, accuracy_scores_lr, f1_scores_lr, 'LR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.35177782453187"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_accs_autoencoder_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, data, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        precision = precision_score(labels.numpy(), predicted.numpy(), average='weighted')\n",
    "        recall = recall_score(labels.numpy(), predicted.numpy(), average='weighted')\n",
    "        accuracy = accuracy_score(labels.numpy(), predicted.numpy())\n",
    "        f1 = f1_score(labels.numpy(), predicted.numpy())\n",
    "    return precision, recall, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scores_plot(models, title):\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    for i, name in enumerate(names):\n",
    "        model = models[name]\n",
    "\n",
    "        X_train = pd.DataFrame(missing_value_imputation(datas[i]))\n",
    "        X_train = normalize_data(X_train)\n",
    "        X_train = (pd.DataFrame(feature_extraction(X_train).detach().numpy()))\n",
    "        \n",
    "        data = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        label = torch.tensor(labels[i].values, dtype=torch.long)\n",
    "\n",
    "        precision, recall, accuracy, f1 = evaluate_model(model, data, label)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    x = np.arange(len(names))\n",
    "    width = 0.2 \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    rects1 = ax.bar(x - width - width/2, precision_scores, width, label='Precision')\n",
    "    rects2 = ax.bar(x - width/2, recall_scores, width, label='Recall')\n",
    "    rects3 = ax.bar(x + width/2, accuracy_scores, width, label='Accuracy')\n",
    "    rects4 = ax.bar(x + width + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "    ax.set_xlabel('Datasets')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('%.2f' % height,\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0483\n",
      "Epoch [10/10], Loss: 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0583\n",
      "Epoch [10/10], Loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0729\n",
      "Epoch [10/10], Loss: 0.0665\n",
      "Test Loss: 0.1054\n",
      "Epoch [10/10], Loss: 0.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1316\n",
      "Epoch [10/10], Loss: 0.1285\n",
      "Test Loss: 0.0547\n",
      "Epoch [10/10], Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "def evaluate_model(model, data, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        precision = precision_score(labels.numpy(), predicted.numpy(), average='weighted')\n",
    "        recall = recall_score(labels.numpy(), predicted.numpy(), average='weighted')\n",
    "        accuracy = accuracy_score(labels.numpy(), predicted.numpy())\n",
    "        f1 = f1_score(labels.numpy(), predicted.numpy())\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    model = models_cnn[name]\n",
    "    X_train = pd.DataFrame(missing_value_imputation(datas[i]))\n",
    "    X_train = normalize_data(X_train)\n",
    "    X_train = (pd.DataFrame(feature_extraction(X_train).detach().numpy()))\n",
    "    \n",
    "    data = torch.tensor(X_train.values.reshape(int(len(X_train)), 1, X_train.shape[1]), dtype=torch.float32)\n",
    "    label = torch.tensor(labels[i].values, dtype=torch.long)\n",
    "    precision, recall, accuracy, f1 = evaluate_model(model, data, label)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "x = np.arange(len(names))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width - width/2, precision_scores, width, label='Precision')\n",
    "rects2 = ax.bar(x - width/2, recall_scores, width, label='Recall')\n",
    "rects3 = ax.bar(x + width/2, accuracy_scores, width, label='Accuracy')\n",
    "rects4 = ax.bar(x + width + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_title('CNN')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('%.2f' % height,\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0483\n",
      "Epoch [10/10], Loss: 0.0518\n",
      "Test Loss: 0.0584\n",
      "Epoch [10/10], Loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0728\n",
      "Epoch [10/10], Loss: 0.0665\n",
      "Test Loss: 0.1054\n",
      "Epoch [10/10], Loss: 0.1052\n",
      "Test Loss: 0.1315\n",
      "Epoch [10/10], Loss: 0.1284\n",
      "Test Loss: 0.0548\n",
      "Epoch [10/10], Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_scores_plot(models=models_mlp, title='Multilayer Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0482\n",
      "Epoch [10/10], Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0582\n",
      "Epoch [10/10], Loss: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0728\n",
      "Epoch [10/10], Loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1052\n",
      "Epoch [10/10], Loss: 0.1051\n",
      "Test Loss: 0.1316\n",
      "Epoch [10/10], Loss: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0548\n",
      "Epoch [10/10], Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utku/anaconda3/envs/metaboliticsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_scores_plot(models=models_logistic_regression, title='Logistic Regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "778c5b0b8544ccffd5f6322101d309514d83dbe7fc6be5eb2559e1a8cad2027f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
